#!/usr/bin/env python3
"""
Phase 6 å†…å®¹åˆ†ç±»å™¨

è‡ªåŠ¨è¯†åˆ«å’Œåˆ†ç±»å¤šåª’ä½“å†…å®¹ç±»å‹ï¼šlectureã€youtubeã€rssã€podcast
åŸºäºæ–‡ä»¶åã€URLæ¨¡å¼å’Œå†…å®¹ç‰¹å¾è¿›è¡Œæ™ºèƒ½åˆ†ç±»
"""

import re
import logging
from typing import Dict, List, Any, Optional, Tuple
from urllib.parse import urlparse
from pathlib import Path

from src.utils.config import ConfigManager


class ContentClassifier:
    """å†…å®¹åˆ†ç±»å™¨
    
    æ”¯æŒå¤šç§åˆ†ç±»ç­–ç•¥ï¼š
    1. æ–‡ä»¶åæ¨¡å¼åŒ¹é…
    2. URLæ¨¡å¼è¯†åˆ«
    3. å†…å®¹ç‰¹å¾åˆ†æ
    4. ç½®ä¿¡åº¦è®¡ç®—
    5. è‡ªåŠ¨æ ‡ç­¾æå–
    """
    
    def __init__(self, config_manager: ConfigManager):
        """åˆå§‹åŒ–å†…å®¹åˆ†ç±»å™¨
        
        Args:
            config_manager: é…ç½®ç®¡ç†å™¨å®ä¾‹
        """
        self.config_manager = config_manager
        self.logger = logging.getLogger('project_bach.content_classifier')
        
        # åŠ è½½é…ç½®
        self.content_types_config = config_manager.get_content_types_config()
        self.classification_config = config_manager.get_classification_config()
        self.content_filter_config = config_manager.get_content_filter_config()
        
        # è®¾ç½®é»˜è®¤å€¼
        self.confidence_threshold = self.classification_config.get('confidence_threshold', 0.7)
        self.default_category = self.classification_config.get('default_category', 'lecture')
        self.max_content_length = self.classification_config.get('max_content_length', 5000)
        
        # æƒé‡é…ç½®
        weights = self.classification_config.get('scoring_weights', {})
        self.url_weight = weights.get('url_match', 0.6)
        self.filename_weight = weights.get('filename_match', 0.3)
        self.content_weight = weights.get('content_match', 0.1)
        
        # æ ‡ç­¾æå–é…ç½®
        tag_config = self.classification_config.get('tag_extraction', {})
        self.max_tags = tag_config.get('max_tags', 10)
        self.min_tag_length = tag_config.get('min_tag_length', 2)
        self.exclude_common = tag_config.get('exclude_common_words', True)
        
        # å¸¸è§è¯æ±‡åˆ—è¡¨ï¼ˆç”¨äºæ ‡ç­¾è¿‡æ»¤ï¼‰- å¢å¼ºä¸­è‹±åŒè¯­æ”¯æŒ
        self.common_words = {
            # è‹±æ–‡å¸¸è§è¯ï¼ˆä»¥è‹±æ–‡ä¸ºä¸»çš„å†…å®¹ï¼‰
            'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by',
            'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had',
            'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they',
            'will', 'would', 'can', 'could', 'should', 'may', 'might', 'must', 'shall',
            'do', 'does', 'did', 'get', 'got', 'make', 'made', 'take', 'took', 'come', 'came',
            'go', 'went', 'see', 'saw', 'know', 'knew', 'think', 'thought', 'say', 'said',
            'like', 'want', 'need', 'work', 'time', 'way', 'day', 'man', 'thing', 'life',
            'world', 'hand', 'part', 'place', 'case', 'fact', 'right', 'good', 'new', 'first',
            'last', 'long', 'great', 'little', 'own', 'other', 'old', 'same', 'big', 'high',
            'different', 'small', 'large', 'next', 'early', 'young', 'important', 'few', 'public',
            # ä¸­æ–‡å¸¸è§è¯
            'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª',
            'ä¼š', 'è¯´', 'ä»–', 'å¥¹', 'å®ƒ', 'æˆ‘ä»¬', 'ä½ ä»¬', 'ä»–ä»¬', 'è¿™', 'é‚£', 'è¿™ä¸ª', 'é‚£ä¸ª',
            'å¯ä»¥', 'èƒ½å¤Ÿ', 'åº”è¯¥', 'éœ€è¦', 'æƒ³è¦', 'è§‰å¾—', 'è®¤ä¸º', 'çŸ¥é“', 'çœ‹åˆ°', 'å¬åˆ°',
            'éå¸¸', 'å¾ˆ', 'æ¯”è¾ƒ', 'æ›´', 'æœ€', 'ä¹Ÿ', 'è¿˜', 'éƒ½', 'åª', 'å·²ç»', 'æ­£åœ¨', 'å°†è¦'
        }
        
        self.logger.info("ContentClassifieråˆå§‹åŒ–å®Œæˆ")
    
    def classify_by_filename(self, filename: str) -> str:
        """åŸºäºæ–‡ä»¶åè¿›è¡Œåˆ†ç±»
        
        Args:
            filename: æ–‡ä»¶å
            
        Returns:
            åˆ†ç±»ç»“æœ
        """
        if not filename:
            return self.default_category
        
        filename_lower = filename.lower()
        
        # æ£€æŸ¥æ¯ç§å†…å®¹ç±»å‹çš„æ–‡ä»¶åæ¨¡å¼
        for content_type, type_config in self.content_types_config.items():
            patterns = type_config.get('auto_detect_patterns', {}).get('filename', [])
            
            for pattern in patterns:
                if pattern.lower() in filename_lower:
                    self.logger.debug(f"æ–‡ä»¶ååŒ¹é…: {filename} -> {content_type} (æ¨¡å¼: {pattern})")
                    return content_type
        
        return self.default_category
    
    def classify_by_url(self, url: str) -> str:
        """åŸºäºURLè¿›è¡Œåˆ†ç±»
        
        Args:
            url: URLå­—ç¬¦ä¸²
            
        Returns:
            åˆ†ç±»ç»“æœ
        """
        if not url:
            return self.default_category
        
        url_lower = url.lower()
        
        # æ£€æŸ¥æ¯ç§å†…å®¹ç±»å‹çš„URLæ¨¡å¼
        for content_type, type_config in self.content_types_config.items():
            patterns = type_config.get('auto_detect_patterns', {}).get('url', [])
            
            for pattern in patterns:
                if pattern.lower() in url_lower:
                    self.logger.debug(f"URLåŒ¹é…: {url} -> {content_type} (æ¨¡å¼: {pattern})")
                    return content_type
        
        return self.default_category
    
    def classify_by_content(self, content: str) -> str:
        """åŸºäºå†…å®¹ç‰¹å¾è¿›è¡Œåˆ†ç±»
        
        Args:
            content: æ–‡æœ¬å†…å®¹
            
        Returns:
            åˆ†ç±»ç»“æœ
        """
        if not content:
            return self.default_category
        
        # é™åˆ¶å†…å®¹é•¿åº¦ä»¥æé«˜æ€§èƒ½
        if len(content) > self.max_content_length:
            content = content[:self.max_content_length]
        
        content_lower = content.lower()
        best_match = self.default_category
        best_score = 0.0
        
        # æ£€æŸ¥æ¯ç§å†…å®¹ç±»å‹çš„å†…å®¹æ¨¡å¼
        for content_type, type_config in self.content_types_config.items():
            patterns = type_config.get('auto_detect_patterns', {}).get('content', [])
            
            # è®¡ç®—åŒ¹é…åˆ†æ•°
            score = 0.0
            matches = 0
            
            for pattern in patterns:
                if pattern.lower() in content_lower:
                    matches += 1
                    # æ ¹æ®æ¨¡å¼é•¿åº¦ç»™äºˆä¸åŒæƒé‡
                    weight = len(pattern) / 10.0  # è¾ƒé•¿çš„æ¨¡å¼æƒé‡æ›´é«˜
                    score += weight
            
            # å½’ä¸€åŒ–åˆ†æ•°
            if patterns:
                score = score / len(patterns)
            
            if score > best_score:
                best_score = score
                best_match = content_type
        
        self.logger.debug(f"å†…å®¹åˆ†æ: {content[:50]}... -> {best_match} (åˆ†æ•°: {best_score:.3f})")
        return best_match
    
    def extract_tags(self, content: str) -> List[str]:
        """ä»å†…å®¹ä¸­æå–æ ‡ç­¾
        
        Args:
            content: æ–‡æœ¬å†…å®¹
            
        Returns:
            æ ‡ç­¾åˆ—è¡¨
        """
        if not content:
            return []
        
        # é™åˆ¶å†…å®¹é•¿åº¦
        if len(content) > self.max_content_length:
            content = content[:self.max_content_length]
        
        # ç®€å•çš„æ ‡ç­¾æå–ç­–ç•¥
        tags = set()
        
        # 1. æå–æŠ€æœ¯æœ¯è¯­ï¼ˆå¤§å†™å­—æ¯å¼€å¤´çš„è¯ï¼‰
        tech_terms = re.findall(r'\b[A-Z][a-z]+\b', content)
        for term in tech_terms:
            if len(term) >= self.min_tag_length and term.lower() not in self.common_words:
                tags.add(term.lower())
        
        # 2. æå–å…¨å¤§å†™çš„ç¼©å†™
        abbreviations = re.findall(r'\b[A-Z]{2,}\b', content)
        for abbr in abbreviations:
            if len(abbr) >= self.min_tag_length:
                tags.add(abbr.lower())
        
        # 3. æå–ç‰¹æ®Šè¯æ±‡ï¼ˆæŠ€æœ¯ç›¸å…³ï¼‰- å¢å¼ºä¸­è‹±åŒè¯­æ”¯æŒ
        tech_patterns = [
            # æ ¸å¿ƒæŠ€æœ¯è¯æ±‡ï¼ˆè‹±æ–‡ï¼‰
            r'\b(machine|deep|neural|artificial|quantum|computer|software|hardware|programming|algorithm|data|analysis|research|technology|science|engineering|mathematics|physics|chemistry|biology)\b',
            # ç¼–ç¨‹å’Œå¼€å‘ç›¸å…³ï¼ˆè‹±æ–‡ï¼‰
            r'\b(python|javascript|java|cpp|golang|rust|swift|kotlin|typescript|react|vue|angular|node|docker|kubernetes|git|github|api|database|framework|library|cloud|aws|azure|gcp)\b',
            # å­¦ä¹ å’Œæ•™è‚²ç›¸å…³ï¼ˆè‹±æ–‡ï¼‰
            r'\b(tutorial|guide|course|lecture|education|learning|teaching|training|workshop|seminar|presentation|demonstration|walkthrough|howto|documentation|example|practice)\b',
            # AIå’Œæœºå™¨å­¦ä¹ ï¼ˆè‹±æ–‡ï¼‰
            r'\b(ai|ml|nlp|cv|llm|gpt|transformer|bert|cnn|rnn|lstm|gan|reinforcement|supervised|unsupervised|classification|regression|clustering|optimization)\b',
            # ä¸­æ–‡æŠ€æœ¯è¯æ±‡
            r'\b(æœºå™¨å­¦ä¹ |æ·±åº¦å­¦ä¹ |äººå·¥æ™ºèƒ½|ç¥ç»ç½‘ç»œ|é‡å­|è®¡ç®—æœº|è½¯ä»¶|ç¡¬ä»¶|ç¼–ç¨‹|ç®—æ³•|æ•°æ®|åˆ†æ|ç ”ç©¶|æŠ€æœ¯|ç§‘å­¦|å·¥ç¨‹|æ•°å­¦|ç‰©ç†|åŒ–å­¦|ç”Ÿç‰©)\b',
            # ä¸­æ–‡æ•™è‚²è¯æ±‡
            r'\b(æ•™è‚²|å­¦ä¹ |è¯¾ç¨‹|è®²åº§|æ•™ç¨‹|æŒ‡å—|åŸ¹è®­|ç ”è®¨|æ¼”ç¤º|å®è·µ|æ–‡æ¡£|ç¤ºä¾‹|ç»ƒä¹ |çŸ¥è¯†|ç†è®º|æ¦‚å¿µ|åŸç†)\b',
            # ä¸“ä¸šæœ¯è¯­ï¼ˆè‹±æ–‡ï¼‰
            r'\b(development|architecture|design|pattern|methodology|framework|infrastructure|system|platform|solution|implementation|deployment|optimization|performance|security|scalability)\b'
        ]
        
        for pattern in tech_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches:
                if len(match) >= self.min_tag_length and match.lower() not in self.common_words:
                    tags.add(match.lower())
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶é™åˆ¶æ•°é‡
        result_tags = list(tags)[:self.max_tags]
        
        self.logger.debug(f"æå–æ ‡ç­¾: {result_tags}")
        return result_tags
    
    def get_confidence_score(self, content: str, predicted_type: str) -> float:
        """è®¡ç®—åˆ†ç±»ç½®ä¿¡åº¦
        
        Args:
            content: æ–‡æœ¬å†…å®¹
            predicted_type: é¢„æµ‹çš„ç±»å‹
            
        Returns:
            ç½®ä¿¡åº¦åˆ†æ•° (0.0 - 1.0)
        """
        if not content or predicted_type not in self.content_types_config:
            return 0.0
        
        # é™åˆ¶å†…å®¹é•¿åº¦
        if len(content) > self.max_content_length:
            content = content[:self.max_content_length]
        
        content_lower = content.lower()
        type_config = self.content_types_config[predicted_type]
        
        # è®¡ç®—å†…å®¹åŒ¹é…åº¦
        patterns = type_config.get('auto_detect_patterns', {}).get('content', [])
        if not patterns:
            return 0.5  # å¦‚æœæ²¡æœ‰æ¨¡å¼ï¼Œè¿”å›ä¸­ç­‰ç½®ä¿¡åº¦
        
        matches = 0
        total_patterns = len(patterns)
        
        for pattern in patterns:
            if pattern.lower() in content_lower:
                matches += 1
        
        # åŸºç¡€ç½®ä¿¡åº¦ (æé«˜æƒé‡)
        base_confidence = matches / total_patterns
        
        # å†…å®¹é•¿åº¦å› å­ï¼ˆæ›´é•¿çš„å†…å®¹ç½®ä¿¡åº¦æ›´é«˜ï¼‰
        length_factor = min(len(content) / 100, 1.0)  # 100å­—ç¬¦ä»¥ä¸Šå¼€å§‹æœ‰åŠ æˆ
        
        # å…³é”®è¯å¯†åº¦å› å­
        keyword_density = self._calculate_keyword_density(content_lower, patterns)
        
        # ç»¼åˆç½®ä¿¡åº¦ (è°ƒæ•´æƒé‡ä»¥æé«˜åˆ†æ•°)
        confidence = (base_confidence * 0.7 + length_factor * 0.15 + keyword_density * 0.15)
        
        # å¦‚æœæœ‰ä»»ä½•åŒ¹é…ï¼Œç»™äºˆåŸºç¡€åˆ†æ•°ä¿è¯
        if matches > 0:
            confidence = max(confidence, 0.3)  # æœ€ä½ä¿è¯åˆ†æ•°
        
        # å¦‚æœæœ‰å¤šä¸ªåŒ¹é…ï¼Œç»™äºˆé¢å¤–åŠ æˆ
        if matches > 1:
            confidence = min(confidence * 1.3, 1.0)
        
        # ä¸ºé«˜åŒ¹é…åº¦å†…å®¹æä¾›æ›´é«˜çš„åŸºç¡€åˆ†æ•°
        if base_confidence > 0.5:
            confidence = max(confidence, 0.8)
        
        # ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…
        confidence = max(0.0, min(1.0, confidence))
        
        self.logger.debug(f"ç½®ä¿¡åº¦è®¡ç®—: {predicted_type} = {confidence:.3f} (åŒ¹é…: {matches}/{total_patterns})")
        return confidence
    
    def _calculate_keyword_density(self, content: str, patterns: List[str]) -> float:
        """è®¡ç®—å…³é”®è¯å¯†åº¦
        
        Args:
            content: æ–‡æœ¬å†…å®¹
            patterns: æ¨¡å¼åˆ—è¡¨
            
        Returns:
            å…³é”®è¯å¯†åº¦åˆ†æ•°
        """
        if not content or not patterns:
            return 0.0
        
        words = content.split()
        total_words = len(words)
        
        if total_words == 0:
            return 0.0
        
        keyword_count = 0
        for pattern in patterns:
            keyword_count += content.count(pattern.lower())
        
        density = keyword_count / total_words
        return min(density * 10, 1.0)  # å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
    
    def classify_content(self, 
                        filename: Optional[str] = None,
                        content: Optional[str] = None,
                        source_url: Optional[str] = None) -> Dict[str, Any]:
        """ç»¼åˆåˆ†ç±»å†…å®¹
        
        Args:
            filename: æ–‡ä»¶å
            content: æ–‡æœ¬å†…å®¹
            source_url: æ¥æºURL
            
        Returns:
            åˆ†ç±»ç»“æœå­—å…¸
        """
        # æ”¶é›†å„ç§åˆ†ç±»ç»“æœ
        classifications = {}
        
        # URLåˆ†ç±»ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        if source_url:
            url_type = self.classify_by_url(source_url)
            classifications['url'] = url_type
        
        # æ–‡ä»¶ååˆ†ç±»
        if filename:
            filename_type = self.classify_by_filename(filename)
            classifications['filename'] = filename_type
        
        # å†…å®¹åˆ†ç±»
        if content:
            content_type = self.classify_by_content(content)
            classifications['content'] = content_type
        
        # å¦‚æœæ²¡æœ‰ä»»ä½•è¾“å…¥ï¼Œè¿”å›é»˜è®¤åˆ†ç±»
        if not classifications:
            return {
                'content_type': self.default_category,
                'confidence': 0.0,
                'auto_detected': False,
                'tags': [],
                'metadata': self._get_type_metadata(self.default_category),
                'classification_details': {}
            }
        
        # è®¡ç®—åŠ æƒåˆ†æ•°
        type_scores = {}
        
        for method, predicted_type in classifications.items():
            if predicted_type not in type_scores:
                type_scores[predicted_type] = 0.0
            
            # æ ¹æ®æ–¹æ³•åˆ†é…æƒé‡
            if method == 'url':
                type_scores[predicted_type] += self.url_weight
            elif method == 'filename':
                type_scores[predicted_type] += self.filename_weight
            elif method == 'content':
                type_scores[predicted_type] += self.content_weight
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ç±»å‹
        final_type = max(type_scores.items(), key=lambda x: x[1])[0]
        final_score = type_scores[final_type]
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = self.get_confidence_score(content or '', final_type)
        
        # å¦‚æœç½®ä¿¡åº¦å¤ªä½ä¸”æ²¡æœ‰å¼ºæŒ‡ç¤ºï¼ˆå¦‚URLåŒ¹é…ï¼‰ï¼Œä½¿ç”¨é»˜è®¤åˆ†ç±»
        if confidence < self.confidence_threshold and 'url' not in classifications:
            # ä½†æ˜¯å¦‚æœåˆ†ç±»ç»“æœæœ¬èº«å°±æ˜¯é»˜è®¤åˆ†ç±»ï¼Œä¿æŒåŸç½®ä¿¡åº¦
            if final_type != self.default_category:
                final_type = self.default_category
                confidence = 0.5
        
        # æå–æ ‡ç­¾
        tags = self.extract_tags(content or '')
        
        # æ·»åŠ é»˜è®¤æ ‡ç­¾
        default_tags = self.content_types_config.get(final_type, {}).get('default_tags', [])
        tags.extend(default_tags)
        tags = list(set(tags))  # å»é‡
        
        result = {
            'content_type': final_type,
            'confidence': confidence,
            'auto_detected': True,
            'tags': tags,
            'metadata': self._get_type_metadata(final_type),
            'classification_details': {
                'method_results': classifications,
                'type_scores': type_scores,
                'final_score': final_score
            }
        }
        
        self.logger.info(f"å†…å®¹åˆ†ç±»å®Œæˆ: {final_type} (ç½®ä¿¡åº¦: {confidence:.3f})")
        return result
    
    def _get_type_metadata(self, content_type: str) -> Dict[str, Any]:
        """è·å–å†…å®¹ç±»å‹çš„å…ƒæ•°æ®
        
        Args:
            content_type: å†…å®¹ç±»å‹
            
        Returns:
            å…ƒæ•°æ®å­—å…¸
        """
        if content_type not in self.content_types_config:
            content_type = self.default_category
        
        type_config = self.content_types_config[content_type]
        
        return {
            'icon': type_config.get('icon', 'ğŸ“„'),
            'display_name': type_config.get('display_name', content_type.title()),
            'description': type_config.get('description', ''),
            'supported_formats': type_config.get('supported_formats', []),
            'default_tags': type_config.get('default_tags', [])
        }
    
    def validate_content_type(self, content_type: str) -> bool:
        """éªŒè¯å†…å®¹ç±»å‹æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            content_type: å†…å®¹ç±»å‹
            
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        return content_type in self.content_types_config
    
    def get_supported_types(self) -> List[str]:
        """è·å–æ”¯æŒçš„å†…å®¹ç±»å‹åˆ—è¡¨
        
        Returns:
            å†…å®¹ç±»å‹åˆ—è¡¨
        """
        return list(self.content_types_config.keys())
    
    def get_type_info(self, content_type: str) -> Optional[Dict[str, Any]]:
        """è·å–ç‰¹å®šå†…å®¹ç±»å‹çš„è¯¦ç»†ä¿¡æ¯
        
        Args:
            content_type: å†…å®¹ç±»å‹
            
        Returns:
            ç±»å‹ä¿¡æ¯å­—å…¸
        """
        if content_type not in self.content_types_config:
            return None
        
        type_config = self.content_types_config[content_type].copy()
        type_config['metadata'] = self._get_type_metadata(content_type)
        
        return type_config