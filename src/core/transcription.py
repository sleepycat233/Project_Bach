#!/usr/bin/env python3.11
"""
éŸ³é¢‘è½¬å½•æ¨¡å—
è´Ÿè´£éŸ³é¢‘æ–‡ä»¶çš„è½¬å½•å¤„ç†ï¼ŒåŒ…æ‹¬WhisperKité›†æˆå’Œè¯­è¨€æ£€æµ‹
"""

import subprocess
import logging
import time
import threading
import os
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime, timedelta


class TranscriptionService:
    """éŸ³é¢‘è½¬å½•æœåŠ¡"""
    
    def __init__(self, whisperkit_config: Dict[str, Any]):
        """åˆå§‹åŒ–è½¬å½•æœåŠ¡
        
        Args:
            whisperkit_config: WhisperKité…ç½®å­—å…¸
        """
        self.config = whisperkit_config
        self.logger = logging.getLogger('project_bach.transcription')
        self.whisperkit_client = WhisperKitClient(whisperkit_config)
        
    def transcribe_audio(self, audio_path: Path, prompt: str = None, language_preference: str = 'english', 
                        custom_model: str = None, custom_model_prefix: str = None) -> str:
        """è½¬å½•éŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            prompt: Whisperç³»ç»Ÿæç¤ºè¯ï¼Œç”¨äºæé«˜ç‰¹å®šæœ¯è¯­è¯†åˆ«å‡†ç¡®æ€§
            language_preference: è¯­è¨€åå¥½ ('english' æˆ– 'multilingual')
            custom_model: è‡ªå®šä¹‰æ¨¡å‹åç§° (å¦‚'tiny', 'medium', 'large-v3')
            custom_model_prefix: è‡ªå®šä¹‰æ¨¡å‹å‰ç¼€ (å¦‚'openai', 'distil')
            
        Returns:
            è½¬å½•æ–‡æœ¬
            
        Raises:
            Exception: è½¬å½•å¤±è´¥
        """
        # ä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶
        if custom_model and custom_model_prefix:
            model = custom_model
            model_prefix = custom_model_prefix
            # æ ¹æ®æ¨¡å‹å‰ç¼€ç¡®å®šè¯­è¨€è®¾ç½®
            if custom_model_prefix == 'distil' and language_preference == 'english':
                language = 'en'
            elif custom_model_prefix == 'openai' and language_preference == 'multilingual':
                # WhisperKitä¸æ”¯æŒ'auto'ï¼Œå¤šè¯­è¨€æ¨¡å¼ä½¿ç”¨ç©ºå­—ç¬¦ä¸²è®©å…¶è‡ªåŠ¨æ£€æµ‹
                language = None  # è®©WhisperKitè‡ªåŠ¨æ£€æµ‹
            else:
                # æ ¹æ®è¯­è¨€åå¥½é€‰æ‹©è¯­è¨€ä»£ç 
                language = 'en' if language_preference == 'english' else None
        else:
            # ä½¿ç”¨é…ç½®æ–‡ä»¶çš„é»˜è®¤è®¾ç½®
            language_config = self.config.get('language_configs', {}).get(language_preference, {})
            model = self.config.get('model', 'large-v3')
            model_prefix = language_config.get('model_prefix', 'distil')
            language = language_config.get('language_code', 'en')
        
        # è·å–éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯
        file_size_mb = audio_path.stat().st_size / (1024 * 1024)
        audio_duration = self._estimate_audio_duration(audio_path)
        
        self.logger.info(f"å¼€å§‹è½¬å½•éŸ³é¢‘: {audio_path.name}")
        self.logger.info(f"æ–‡ä»¶ä¿¡æ¯: å¤§å°={file_size_mb:.1f}MB, æ¨¡å‹={model_prefix}-{model}, è¯­è¨€={language}")
        if prompt:
            self.logger.info(f"ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯: {prompt[:50]}{'...' if len(prompt) > 50 else ''}")
        
        # ç¡¬ç¼–ç åˆç†çš„é˜ˆå€¼
        large_file_threshold = 50  # MB
        long_audio_threshold = 30  # åˆ†é’Ÿ
        
        # å¤§æ–‡ä»¶é¢„è­¦
        if file_size_mb > large_file_threshold:
            self.logger.warning(f"æ£€æµ‹åˆ°å¤§éŸ³é¢‘æ–‡ä»¶ ({file_size_mb:.1f}MB > {large_file_threshold}MB)ï¼Œè½¬å½•å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´")
        
        if audio_duration > long_audio_threshold:
            self.logger.warning(f"æ£€æµ‹åˆ°é•¿éŸ³é¢‘æ–‡ä»¶ ({audio_duration:.1f}åˆ†é’Ÿ > {long_audio_threshold}åˆ†é’Ÿ)ï¼Œå»ºè®®è€ƒè™‘åˆ†æ®µå¤„ç†")
            # ä¸ºè¶…é•¿éŸ³é¢‘æä¾›å¤„ç†å»ºè®®
            if audio_duration > 60:  # è¶…è¿‡1å°æ—¶
                self.logger.warning("ğŸ“‹ å¤§æ–‡ä»¶å¤„ç†å»ºè®®:")
                self.logger.warning("   1. æ¨èä½¿ç”¨tinyæˆ–baseæ¨¡å‹ä»¥å‡å°‘å¤„ç†æ—¶é—´")
                self.logger.warning("   2. è€ƒè™‘å°†éŸ³é¢‘åˆ†å‰²ä¸º30åˆ†é’Ÿçš„ç‰‡æ®µ")
                self.logger.warning("   3. å¢åŠ ç³»ç»Ÿå¯ç”¨å†…å­˜å’Œå¤„ç†å™¨èµ„æº")
                self.logger.warning("   4. è®¾ç½®è¶³å¤Ÿçš„å¤„ç†è¶…æ—¶æ—¶é—´")
        
        try:
            # ä½¿ç”¨WhisperKit CLIè¿›è¡ŒçœŸå®è½¬å½•ï¼Œä¼ é€’è®¡ç®—å‡ºçš„å®é™…å‚æ•°
            return self.whisperkit_client.transcribe(
                audio_path=audio_path, 
                audio_duration=audio_duration, 
                prompt=prompt, 
                model=model, 
                model_prefix=model_prefix, 
                language=language
            )
        except Exception as e:
            self.logger.warning(f"WhisperKitè½¬å½•å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ: {str(e)}")
            return self._fallback_transcription(audio_path)
    
    def _fallback_transcription(self, audio_path: Path) -> str:
        """å¤‡ç”¨è½¬å½•æ–¹æ¡ˆï¼ˆæ¨¡æ‹Ÿè½¬å½•ï¼‰
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ¨¡æ‹Ÿè½¬å½•æ–‡æœ¬
        """
        self.logger.info("ä½¿ç”¨å¤‡ç”¨è½¬å½•æ–¹æ¡ˆ")
        
        # ä¿ç•™åŸæœ‰çš„æ¨¡æ‹Ÿè½¬å½•é€»è¾‘ä½œä¸ºå¤‡ä»½
        if "meeting" in audio_path.name.lower():
            transcript = f"""
è¿™æ˜¯ä¸€ä¸ªå…³äºé¡¹ç›®è¿›å±•çš„ä¼šè®®è½¬å½•ï¼Œæ¥è‡ªæ–‡ä»¶ {audio_path.name}ã€‚
å¼ ä¸‰é¦–å…ˆæ±‡æŠ¥äº†ä¸Šå‘¨çš„å·¥ä½œè¿›å±•ï¼Œä¸»è¦å®Œæˆäº†ç³»ç»Ÿæ¶æ„è®¾è®¡ã€‚
æå››æåˆ°äº†åœ¨å®æ–½è¿‡ç¨‹ä¸­é‡åˆ°çš„æŠ€æœ¯éš¾é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥ç ”ç©¶ã€‚
ç‹äº”å»ºè®®é‡‡ç”¨æ–°çš„æŠ€æœ¯æ–¹æ¡ˆæ¥è§£å†³æ€§èƒ½é—®é¢˜ã€‚
èµµå…­è´Ÿè´£åè°ƒå„éƒ¨é—¨ä¹‹é—´çš„é…åˆå·¥ä½œã€‚
ä¼šè®®æŒç»­äº†å¤§çº¦45åˆ†é’Ÿï¼Œæœ€ç»ˆç¡®å®šäº†ä¸‹ä¸€é˜¶æ®µçš„å·¥ä½œè®¡åˆ’ã€‚
ä¸»è¦å†³ç­–åŒ…æ‹¬ï¼šæŠ€æœ¯æ¶æ„ä¼˜åŒ–ã€äººå‘˜åˆ†å·¥è°ƒæ•´ã€æ—¶é—´èŠ‚ç‚¹ç¡®è®¤ã€‚
            """.strip()
        elif "lecture" in audio_path.name.lower():
            transcript = f"""
è¿™æ˜¯ä¸€å ‚æŠ€æœ¯è®²åº§çš„è½¬å½•å†…å®¹ï¼Œæ¥è‡ªæ–‡ä»¶ {audio_path.name}ã€‚
æ•™æˆé™ˆæ˜è¯¦ç»†ä»‹ç»äº†äººå·¥æ™ºèƒ½åœ¨ç°ä»£è½¯ä»¶å¼€å‘ä¸­çš„åº”ç”¨ã€‚
å­¦ç”Ÿåˆ˜åæé—®å…³äºæœºå™¨å­¦ä¹ ç®—æ³•çš„é€‰æ‹©é—®é¢˜ã€‚
åŠ©æ•™å­™ä¸½å›ç­”äº†å…³äºæ•°æ®é¢„å¤„ç†çš„å…·ä½“æ–¹æ³•ã€‚
è®²åº§æ¶µç›–äº†ç†è®ºåŸºç¡€ã€å®è·µæ¡ˆä¾‹å’Œæœªæ¥å‘å±•è¶‹åŠ¿ã€‚
è¯¾ç¨‹æ—¶é•¿çº¦60åˆ†é’Ÿï¼ŒåŒ…å«15åˆ†é’Ÿçš„é—®ç­”ç¯èŠ‚ã€‚
            """.strip()
        else:
            transcript = f"""
WhisperKitè½¬å½•å¤‡ç”¨æ–¹æ¡ˆ - æ–‡ä»¶: {audio_path.name}
ç³»ç»Ÿå·²å°è¯•ä½¿ç”¨WhisperKitè¿›è¡ŒçœŸå®éŸ³é¢‘è½¬å½•ï¼Œä½†é‡åˆ°æŠ€æœ¯é—®é¢˜ã€‚
å»ºè®®æ£€æŸ¥ï¼š1) WhisperKit CLIæ˜¯å¦æ­£ç¡®å®‰è£… 2) éŸ³é¢‘æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ 3) ç³»ç»Ÿèµ„æºæ˜¯å¦å……è¶³
å¦‚éœ€æŠ€æœ¯æ”¯æŒï¼Œè¯·æä¾›æ—¥å¿—æ–‡ä»¶ä»¥ä¾¿è¿›ä¸€æ­¥è¯Šæ–­ã€‚
å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
            """.strip()
        
        # è®°å½•å¤‡ç”¨è½¬å½•ç»“æœé¢„è§ˆ
        preview = transcript[:50] + "..." if len(transcript) > 50 else transcript
        self.logger.info(f"å¤‡ç”¨è½¬å½•å®Œæˆï¼Œæ–‡æœ¬é•¿åº¦: {len(transcript)} å­—ç¬¦ï¼Œå†…å®¹é¢„è§ˆ: {preview}")
        return transcript
    
    def _estimate_audio_duration(self, audio_path: Path) -> float:
        """ä¼°ç®—éŸ³é¢‘æ–‡ä»¶æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            ä¼°ç®—çš„éŸ³é¢‘æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
        """
        try:
            # å°è¯•ä½¿ç”¨ffprobeè·å–ç²¾ç¡®æ—¶é•¿
            cmd = ["ffprobe", "-i", str(audio_path), "-show_entries", "format=duration", 
                   "-v", "quiet", "-of", "csv=p=0"]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0 and result.stdout.strip():
                duration_seconds = float(result.stdout.strip())
                duration_minutes = duration_seconds / 60.0
                self.logger.debug(f"ffprobeæ£€æµ‹éŸ³é¢‘æ—¶é•¿: {duration_minutes:.1f}åˆ†é’Ÿ")
                return duration_minutes
                
        except (subprocess.TimeoutExpired, subprocess.CalledProcessError, ValueError, FileNotFoundError):
            self.logger.debug("ffprobeä¸å¯ç”¨ï¼Œä½¿ç”¨æ–‡ä»¶å¤§å°ä¼°ç®—æ—¶é•¿")
        
        # å¤‡ç”¨æ–¹æ¡ˆï¼šåŸºäºæ–‡ä»¶å¤§å°ä¼°ç®—ï¼ˆç»éªŒå…¬å¼ï¼‰
        file_size_mb = audio_path.stat().st_size / (1024 * 1024)
        # å‡è®¾å¹³å‡æ¯”ç‰¹ç‡çº¦64kbpsï¼ˆé€‚ä¸­è´¨é‡ï¼‰ï¼Œ1MB â‰ˆ 2åˆ†é’Ÿ
        estimated_minutes = file_size_mb * 2.0
        self.logger.debug(f"åŸºäºæ–‡ä»¶å¤§å°ä¼°ç®—éŸ³é¢‘æ—¶é•¿: {estimated_minutes:.1f}åˆ†é’Ÿ")
        return estimated_minutes


class WhisperKitClient:
    """WhisperKit CLIå®¢æˆ·ç«¯"""
    
    def __init__(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–WhisperKitå®¢æˆ·ç«¯
        
        Args:
            config: WhisperKité…ç½®å­—å…¸
        """
        self.config = config
        self.logger = logging.getLogger('project_bach.whisperkit')
    
    def _ensure_model_available(self, base_model_path: str, model_path: str, model: str, model_prefix: str):
        """ç¡®ä¿æ¨¡å‹å¯ç”¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨ä¸‹è½½"""
        import os
        from pathlib import Path
        
        # ç¡®ä¿æ¨¡å‹ç›®å½•å­˜åœ¨
        model_dir = Path(base_model_path)
        model_dir.mkdir(parents=True, exist_ok=True)
        
        # æ£€æŸ¥æœŸæœ›çš„æ¨¡å‹æ˜¯å¦å­˜åœ¨ (model_path å·²ç»æ˜¯å®Œæ•´çš„æ¨¡å‹è·¯å¾„)
        expected_model_name = f"{model_prefix}-{model}" if model_prefix else model
        expected_model_dir = Path(model_path)
        
        if expected_model_dir.exists():
            self.logger.debug(f"æ¨¡å‹å·²å­˜åœ¨: {expected_model_dir}")
            return
        
        # æ¨¡å‹ä¸å­˜åœ¨ï¼Œéœ€è¦ä¸‹è½½
        self.logger.info(f"ğŸ”„ æ¨¡å‹æ–‡ä»¶å¤¹ {expected_model_dir.name} ä¸å­˜åœ¨ï¼ŒWhisperKitå°†è‡ªåŠ¨ä¸‹è½½")
        self.logger.info("â³ é¦–æ¬¡è½¬å½•æ—¶ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ...")
        
    def transcribe(self, audio_path: Path, audio_duration: float = None, prompt: str = None, model: str = None, model_prefix: str = None, language: str = None) -> str:
        """ä½¿ç”¨WhisperKit CLIè¿›è¡ŒéŸ³é¢‘è½¬å½•
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            audio_duration: éŸ³é¢‘æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰ï¼Œç”¨äºè®¡ç®—åˆé€‚çš„è¶…æ—¶æ—¶é—´
            prompt: Whisperç³»ç»Ÿæç¤ºè¯ï¼Œç”¨äºæé«˜ç‰¹å®šæœ¯è¯­è¯†åˆ«å‡†ç¡®æ€§
            model: WhisperKitæ¨¡å‹åç§°ï¼ˆå¦‚'large-v3', 'tiny'ç­‰ï¼‰
            model_prefix: æ¨¡å‹å‰ç¼€ï¼ˆå¦‚'openai', 'distil'ï¼‰
            language: è¯­è¨€ä»£ç ï¼ˆå¦‚'en', 'zh'ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹ï¼‰
            
        Returns:
            è½¬å½•æ–‡æœ¬
            
        Raises:
            Exception: è½¬å½•å¤±è´¥
        """
        # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰ä¼ å…¥åˆ™ä½¿ç”¨é»˜è®¤å€¼
        if model is None:
            model = self.config.get('model', 'large-v3')
        if model_prefix is None:
            model_prefix = 'openai'  # é»˜è®¤ä½¿ç”¨OpenAIæ¨¡å‹
        # language å‚æ•°ç›´æ¥ä½¿ç”¨ä¼ å…¥å€¼ï¼ŒNoneè¡¨ç¤ºè®©WhisperKitè‡ªåŠ¨æ£€æµ‹
        
        # è·å–æ¨¡å‹è·¯å¾„å¹¶ç¡®ä¿æ¨¡å‹å­˜åœ¨
        base_model_path = self.config.get('model_path', './models')
        model_container_path = f"{base_model_path}/whisperkit-coreml"
        
        # æ ¹æ®å®é™…æ–‡ä»¶å¤¹å‘½åçº¦å®šæ„å»ºæ¨¡å‹è·¯å¾„
        # å®é™…æ¨¡å‹æ–‡ä»¶å¤¹å‘½åè§„å¾‹ï¼š
        # - distil-whisper_distil-large-v3
        # - openai_whisper-large-v3-v20240930
        # - openai_whisper-large-v3  
        # - openai_whisper-medium
        if model_prefix == 'distil' and model == 'large-v3':
            # ç‰¹æ®Šæƒ…å†µï¼šdistilæ¨¡å‹ä½¿ç”¨ä¸åŒçš„å‘½åçº¦å®š
            model_folder_name = "distil-whisper_distil-large-v3"
        elif model_prefix == 'openai':
            # OpenAIæ¨¡å‹ä½¿ç”¨æ ‡å‡†å‘½åçº¦å®š
            model_folder_name = f"openai_whisper-{model}"
        else:
            # é»˜è®¤å‘½åçº¦å®šï¼ˆå‘åå…¼å®¹ï¼‰
            model_folder_name = f"{model_prefix}_whisper-{model}"
        
        model_path = f"{model_container_path}/{model_folder_name}"
        self._ensure_model_available(base_model_path, model_path, model, model_prefix)
        
        # ç¡¬ç¼–ç åˆç†çš„è¶…æ—¶å‚æ•°
        base_timeout = 120  # 2åˆ†é’ŸåŸºç¡€è¶…æ—¶
        max_timeout = 7200  # 2å°æ—¶æœ€å¤§è¶…æ—¶
        processing_factors = {
            'tiny': 5, 'base': 8, 'small': 10, 'medium': 15, 'large': 20
        }
        
        # åŠ¨æ€è®¡ç®—è¶…æ—¶æ—¶é—´ï¼šåŸºç¡€æ—¶é—´ + éŸ³é¢‘æ—¶é•¿çš„å€æ•°
        if audio_duration:
            processing_factor = processing_factors.get(model, 15)
            estimated_timeout = int(audio_duration * processing_factor + base_timeout)
            timeout = min(max(estimated_timeout, 300), max_timeout)  # è‡³å°‘5åˆ†é’Ÿï¼Œæœ€å¤šmax_timeout
            self.logger.info(f"æ ¹æ®éŸ³é¢‘æ—¶é•¿({audio_duration:.1f}åˆ†é’Ÿ)è®¡ç®—è¶…æ—¶æ—¶é—´: {timeout}ç§’ (å› å­={processing_factor})")
        else:
            timeout = base_timeout
        
        
        # ç¡¬ç¼–ç æœ€ä¼˜æ€§èƒ½è®¾ç½®
        audio_compute = 'cpuAndNeuralEngine'  # Apple Siliconæœ€ä¼˜
        text_compute = 'cpuAndNeuralEngine'   # ç¥ç»å¼•æ“åŠ é€Ÿ
        use_cache = True                      # å¯ç”¨é¢„å¡«å……ç¼“å­˜
        chunking = 'vad'                     # è¯­éŸ³æ´»åŠ¨æ£€æµ‹
        workers = 2                          # é•¿éŸ³é¢‘ä¼˜åŒ–å¹¶å‘æ•°
        
        
        # æ„å»ºWhisperKitå‘½ä»¤
        cmd = [
            "whisperkit-cli",
            "transcribe",
            "--audio-path", str(audio_path),
            "--model", model,
            "--model-prefix", model_prefix,
            "--task", "transcribe",
            "--audio-encoder-compute-units", audio_compute,
            "--text-decoder-compute-units", text_compute,
            "--chunking-strategy", chunking,
            "--concurrent-worker-count", str(workers)
        ]
        
        # åªæœ‰æ¨¡å‹å­˜åœ¨æ—¶æ‰æŒ‡å®šmodel-pathï¼Œå¦åˆ™è®©WhisperKitè‡ªåŠ¨ä¸‹è½½
        if Path(model_path).exists():
            cmd.extend(["--model-path", model_path])
            self.logger.debug(f"Using local model: {model_path}")
        else:
            cmd.extend(["--download-model-path", base_model_path])
            self.logger.info(f"Model not found, will auto-download to: {base_model_path}")
        
        # æ·»åŠ è¯­è¨€å‚æ•°
        if language:
            cmd.extend(["--language", language])
        
        # æ·»åŠ promptå‚æ•°
        if prompt and prompt.strip():
            cmd.extend(["--prompt", prompt.strip()])
        
        # æ·»åŠ æ€§èƒ½ä¼˜åŒ–é€‰é¡¹
        if use_cache:
            cmd.append("--use-prefill-cache")
        
        self.logger.debug(f"WhisperKit command: {' '.join(cmd)}")
        self.logger.info("ğŸš€ WhisperKit transcription config:")
        self.logger.info(f"   Model: {model_prefix}-{model}, Language: {language or 'auto'}")
        self.logger.info(f"   Compute units: audio={audio_compute}, text={text_compute}")
        self.logger.info(f"   Optimization: cache={'âœ…' if use_cache else 'âŒ'}, chunking={chunking}, workers={workers}")
        self.logger.info(f"   Timeout limit: {timeout//60}m{timeout%60}s")
        
        # å¯åŠ¨è¿›åº¦ç›‘æ§
        start_time = time.time()
        stop_event = threading.Event()
        progress_thread = threading.Thread(target=self._monitor_progress, args=(start_time, timeout, audio_path.name, stop_event))
        progress_thread.daemon = True
        progress_thread.start()
        
        # æ‰§è¡Œè½¬å½•
        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=timeout
            )
        except subprocess.TimeoutExpired:
            stop_event.set()  # åœæ­¢è¿›åº¦ç›‘æ§
            elapsed = time.time() - start_time
            raise Exception(f"WhisperKit transcription timeout (ran {elapsed//60:.0f}m{elapsed%60:.0f}s, timeout limit {timeout}s)")
        
        elapsed_time = time.time() - start_time
        
        if result.returncode != 0:
            stop_event.set()  # åœæ­¢è¿›åº¦ç›‘æ§
            raise Exception(f"WhisperKitæ‰§è¡Œå¤±è´¥: {result.stderr}")
        
        # æå–è½¬å½•æ–‡æœ¬
        transcript = result.stdout.strip()
        
        if not transcript or len(transcript.strip()) < 5:
            stop_event.set()  # åœæ­¢è¿›åº¦ç›‘æ§
            raise Exception("è½¬å½•ç»“æœä¸ºç©ºæˆ–è¿‡çŸ­")
        
        # è®¡ç®—è½¬å½•æ€§èƒ½æŒ‡æ ‡
        words_count = len(transcript.split())
        chars_count = len(transcript)
        words_per_second = words_count / elapsed_time if elapsed_time > 0 else 0
        chars_per_second = chars_count / elapsed_time if elapsed_time > 0 else 0
        
        # è®°å½•è½¬å½•ç»“æœå’Œæ€§èƒ½
        preview = transcript[:80].replace('\n', ' ') + "..." if len(transcript) > 80 else transcript
        # åœæ­¢è¿›åº¦ç›‘æ§çº¿ç¨‹
        stop_event.set()
        
        self.logger.info("âœ… WhisperKit transcription completed!")
        self.logger.info(f"ğŸ“Š Performance metrics: time={elapsed_time:.1f}s, speed={words_per_second:.1f}words/s, {chars_per_second:.1f}chars/s")
        self.logger.info(f"ğŸ“„ Result stats: {words_count} words, {chars_count} characters, preview: {preview}")
        
        return transcript
    
    def _monitor_progress(self, start_time: float, timeout: int, filename: str, stop_event: threading.Event):
        """ç›‘æ§è½¬å½•è¿›åº¦å¹¶å®šæœŸè¾“å‡ºçŠ¶æ€
        
        Args:
            start_time: å¼€å§‹æ—¶é—´æˆ³
            timeout: æ€»è¶…æ—¶æ—¶é—´
            filename: æ–‡ä»¶å
            stop_event: åœæ­¢äº‹ä»¶ä¿¡å·
        """
        # ç¡¬ç¼–ç åˆç†çš„è¿›åº¦æŠ¥å‘Šé—´éš”
        intervals = [30, 60, 120, 300, 600]  # 30ç§’, 1åˆ†é’Ÿ, 2åˆ†é’Ÿ, 5åˆ†é’Ÿ, 10åˆ†é’Ÿ
        
        for interval in intervals:
            # ä½¿ç”¨wait()è€Œésleep()ï¼Œè¿™æ ·å¯ä»¥ç«‹å³å“åº”stop_event
            if stop_event.wait(timeout=interval):
                # æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡ºç›‘æ§
                break
                
            elapsed = time.time() - start_time
            
            if elapsed >= timeout:
                break
                
            remaining = timeout - elapsed
            progress_percent = (elapsed / timeout) * 100
            
            # Display real-time processing status
            self.logger.info(f"ğŸ”„ Transcription in progress: {filename}")
            self.logger.info(f"â±ï¸  Elapsed time: {self._format_time(elapsed)} | Timeout progress: {progress_percent:.1f}%")
            
            # Provide suggestions if nearing timeout
            if remaining < 120:  # Last 2 minutes
                self.logger.warning("âš ï¸  Transcription nearing timeout, consider:")
                self.logger.warning("   1. Use smaller WhisperKit model (e.g. tiny/base)")
                self.logger.warning("   2. Process long audio files in segments")
                self.logger.warning("   3. Increase processing timeout configuration")
    
    def _format_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
        
        Args:
            seconds: ç§’æ•°
            
        Returns:
            æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²
        """
        if seconds < 60:
            return f"{seconds:.0f}ç§’"
        elif seconds < 3600:
            return f"{seconds//60:.0f}åˆ†{seconds%60:.0f}ç§’"
        else:
            return f"{seconds//3600:.0f}å°æ—¶{(seconds%3600)//60:.0f}åˆ†{seconds%60:.0f}ç§’"



class TranscriptionValidator:
    """è½¬å½•ç»“æœéªŒè¯å™¨"""
    
    @staticmethod
    def validate_transcript(transcript: str) -> bool:
        """éªŒè¯è½¬å½•ç»“æœçš„æœ‰æ•ˆæ€§
        
        Args:
            transcript: è½¬å½•æ–‡æœ¬
            
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        if not transcript or not isinstance(transcript, str):
            return False
        
        # æ£€æŸ¥æœ€å°é•¿åº¦
        if len(transcript.strip()) < 5:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ„ä¹‰çš„å†…å®¹ï¼ˆä¸åªæ˜¯ç©ºç™½å­—ç¬¦ï¼‰
        meaningful_chars = sum(1 for c in transcript if c.isalnum() or c in 'ï¼Œã€‚ï¼ï¼Ÿ,.')
        if meaningful_chars < 3:
            return False
        
        return True
    
    @staticmethod
    def clean_transcript(transcript: str) -> str:
        """æ¸…ç†è½¬å½•æ–‡æœ¬
        
        Args:
            transcript: åŸå§‹è½¬å½•æ–‡æœ¬
            
        Returns:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        if not transcript:
            return ""
        
        # å…ˆæŒ‰è¡Œå¤„ç†ï¼Œç§»é™¤æ ‡è®°è¡Œ
        lines = transcript.split('\n')
        content_lines = []
        
        for line in lines:
            line = line.strip()
            # è·³è¿‡æ—¶é—´æˆ³å’Œå…¶ä»–æ ‡è®°è¡Œ
            if line and not line.startswith('[') and not line.startswith('>>'):
                # æ¸…ç†è¡Œå†…å¤šä½™ç©ºæ ¼
                import re
                line = re.sub(r'\s+', ' ', line)
                content_lines.append(line)
        
        # åˆå¹¶è¡Œå¹¶æ¸…ç†å¤šä½™ç©ºç™½
        result = '\n'.join(content_lines)
        
        # ç§»é™¤å¤šä½™çš„è¿ç»­æ¢è¡Œç¬¦ï¼Œä½†ä¿ç•™å¿…è¦çš„æ¢è¡Œ
        result = re.sub(r'\n\s*\n+', '\n', result)
        
        return result.strip()