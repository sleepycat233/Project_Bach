#!/usr/bin/env python3.11
"""
å†…å®¹æ ¼å¼åŒ–æœåŠ¡
è´Ÿè´£å°†éŸ³é¢‘å¤„ç†ç»“æœæ ¼å¼åŒ–ä¸ºWebå‘å¸ƒæ ¼å¼
"""

import markdown
import logging
import json
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
from pathlib import Path
import re
import html

from src.utils.config import ConfigManager


class ContentFormatter:
    """å†…å®¹æ ¼å¼åŒ–æœåŠ¡
    
    Phase 6 å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒå¤šåª’ä½“å†…å®¹ç±»å‹çš„ä¸“é—¨æ ¼å¼åŒ–:
    - lecture (ğŸ“ å­¦æœ¯è®²åº§)
    - youtube (ğŸ“º YouTubeè§†é¢‘) 
    - rss (ğŸ“° RSSæ–‡ç« )
    - podcast (ğŸ™ï¸ æ’­å®¢å†…å®¹)
    """
    
    def __init__(self, config: Dict[str, Any], config_manager: Optional[ConfigManager] = None):
        """åˆå§‹åŒ–å†…å®¹æ ¼å¼åŒ–æœåŠ¡
        
        Args:
            config: æ ¼å¼åŒ–é…ç½®
            config_manager: é…ç½®ç®¡ç†å™¨å®ä¾‹ï¼ˆç”¨äºè·å–å†…å®¹ç±»å‹é…ç½®ï¼‰
        """
        self.config = config
        self.config_manager = config_manager
        self.logger = logging.getLogger('project_bach.content_formatter')
        
        # åŠ è½½å†…å®¹ç±»å‹é…ç½®
        if config_manager:
            try:
                self.content_types_config = config_manager.get_content_types_config()
                self.classification_config = config_manager.get_classification_config()
                self.logger.info(f"åŠ è½½å†…å®¹ç±»å‹é…ç½®: {list(self.content_types_config.keys())}")
            except Exception as e:
                self.logger.warning(f"æ— æ³•åŠ è½½å†…å®¹ç±»å‹é…ç½®: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                self.content_types_config = self._get_default_content_types()
                self.classification_config = {}
        else:
            self.content_types_config = self._get_default_content_types()
            self.classification_config = {}
        
        # é…ç½®Markdownæ‰©å±•
        self.markdown_extensions = [
            'markdown.extensions.extra',     # é¢å¤–è¯­æ³•æ”¯æŒ
            'markdown.extensions.codehilite', # ä»£ç é«˜äº®
            'markdown.extensions.toc',       # ç›®å½•ç”Ÿæˆ
            'markdown.extensions.tables',    # è¡¨æ ¼æ”¯æŒ
        ]
        
        # åˆå§‹åŒ–Markdownå¤„ç†å™¨
        self.md_processor = markdown.Markdown(
            extensions=self.markdown_extensions,
            extension_configs={
                'codehilite': {
                    'css_class': 'highlight',
                    'use_pygments': True
                },
                'toc': {
                    'anchorlink': True
                }
            }
        )
        
        self.logger.info("Phase 6 å†…å®¹æ ¼å¼åŒ–æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    def format_content(self, content_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–å¤šåª’ä½“å†…å®¹å¤„ç†ç»“æœä¸ºå‘å¸ƒå†…å®¹
        
        Phase 6 å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒä¸åŒå†…å®¹ç±»å‹çš„ä¸“é—¨æ ¼å¼åŒ–
        
        Args:
            content_data: å¤šåª’ä½“å†…å®¹å¤„ç†ç»“æœæ•°æ®
            
        Returns:
            æ ¼å¼åŒ–åçš„å†…å®¹
        """
        self.logger.info(f"æ ¼å¼åŒ–å†…å®¹: {content_data.get('title', 'æœªçŸ¥')}")
        
        try:
            # éªŒè¯è¾“å…¥æ•°æ®
            validation_result = self.validate_content_structure(content_data)
            if not validation_result['valid']:
                raise ValueError(f"å†…å®¹ç»“æ„æ— æ•ˆ: {validation_result['message']}")
            
            # æ£€æµ‹å’Œåº”ç”¨å†…å®¹ç±»å‹ç‰¹å®šæ ¼å¼åŒ–
            content_type = self._detect_content_type(content_data)
            self.logger.info(f"æ£€æµ‹åˆ°å†…å®¹ç±»å‹: {content_type}")
            
            # ç”Ÿæˆç±»å‹ç‰¹å®šçš„Markdownå†…å®¹
            markdown_content = self._generate_type_specific_markdown(content_data, content_type)
            
            # è½¬æ¢ä¸ºHTML
            html_content = self.generate_html_from_markdown(markdown_content)
            
            # æå–å…ƒæ•°æ®
            metadata = self._extract_metadata(content_data)
            
            # ç”Ÿæˆæ–‡ä»¶å
            filename = self._generate_filename(content_data)
            
            return {
                'success': True,
                'content': {
                    'markdown': markdown_content,
                    'html': html_content,
                    'metadata': metadata,
                    'filename': filename,
                    'title': content_data['title'],
                    'content_type': content_type,
                    'formatted_time': datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            self.logger.error(f"å†…å®¹æ ¼å¼åŒ–å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _get_default_content_types(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤å†…å®¹ç±»å‹é…ç½®ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰
        
        Returns:
            é»˜è®¤å†…å®¹ç±»å‹é…ç½®
        """
        return {
            'lecture': {
                'icon': 'ğŸ“',
                'display_name': 'è®²åº§',
                'description': 'å­¦æœ¯è®²åº§ã€è¯¾ç¨‹å½•éŸ³ã€æ•™è‚²å†…å®¹'
            },
            'youtube': {
                'icon': 'ğŸ“º', 
                'display_name': 'è§†é¢‘',
                'description': 'YouTubeè§†é¢‘å†…å®¹ã€æ•™å­¦è§†é¢‘ã€æŠ€æœ¯åˆ†äº«'
            },
            'rss': {
                'icon': 'ğŸ“°',
                'display_name': 'æ–‡ç« ', 
                'description': 'RSSè®¢é˜…æ–‡ç« ã€æŠ€æœ¯åšå®¢ã€æ–°é—»èµ„è®¯'
            },
            'podcast': {
                'icon': 'ğŸ™ï¸',
                'display_name': 'æ’­å®¢',
                'description': 'æ’­å®¢èŠ‚ç›®ã€è®¿è°ˆå†…å®¹ã€è®¨è®ºèŠ‚ç›®'
            }
        }
    
    def _detect_content_type(self, content_data: Dict[str, Any]) -> str:
        """æ£€æµ‹å†…å®¹ç±»å‹
        
        Args:
            content_data: å†…å®¹æ•°æ®
            
        Returns:
            æ£€æµ‹åˆ°çš„å†…å®¹ç±»å‹
        """
        # ä¼˜å…ˆä½¿ç”¨å·²æœ‰çš„åˆ†ç±»ç»“æœ
        if 'classification_result' in content_data:
            classification = content_data['classification_result']
            if isinstance(classification, dict) and 'content_type' in classification:
                return classification['content_type']
        
        # å¦‚æœæœ‰ç›´æ¥çš„content_typeå­—æ®µ
        if 'content_type' in content_data:
            return content_data['content_type']
        
        # åŸºäºæ–‡ä»¶åæˆ–å…¶ä»–ä¿¡æ¯è¿›è¡Œç®€å•æ¨æ–­
        original_file = content_data.get('original_file', '').lower()
        
        if any(keyword in original_file for keyword in ['youtube', 'video', 'tutorial']):
            return 'youtube'
        elif any(keyword in original_file for keyword in ['rss', 'feed', 'article', 'news']):
            return 'rss'
        elif any(keyword in original_file for keyword in ['podcast', 'interview', 'talk']):
            return 'podcast'
        elif any(keyword in original_file for keyword in ['lecture', 'course', 'professor', 'class']):
            return 'lecture'
        
        # é»˜è®¤ä¸ºlectureç±»å‹
        return 'lecture'
    
    def _generate_type_specific_markdown(self, content_data: Dict[str, Any], content_type: str) -> str:
        """ç”Ÿæˆç±»å‹ç‰¹å®šçš„Markdownå†…å®¹
        
        Args:
            content_data: å†…å®¹æ•°æ®
            content_type: å†…å®¹ç±»å‹
            
        Returns:
            ç±»å‹ç‰¹å®šçš„Markdownå†…å®¹
        """
        # è·å–ç±»å‹é…ç½®
        type_config = self.content_types_config.get(content_type, {})
        type_icon = type_config.get('icon', 'ğŸ“„')
        type_name = type_config.get('display_name', content_type.title())
        
        # æ ¹æ®ç±»å‹ç”Ÿæˆä¸åŒçš„å†…å®¹ç»“æ„
        if content_type == 'youtube':
            return self._generate_youtube_markdown(content_data, type_icon, type_name)
        elif content_type == 'rss':
            return self._generate_rss_markdown(content_data, type_icon, type_name)
        elif content_type == 'podcast':
            return self._generate_podcast_markdown(content_data, type_icon, type_name)
        elif content_type == 'lecture':
            return self._generate_lecture_markdown(content_data, type_icon, type_name)
        else:
            # é€šç”¨æ ¼å¼
            return self._generate_generic_markdown(content_data, type_icon, type_name)
    
    def _generate_youtube_markdown(self, content_data: Dict[str, Any], icon: str, type_name: str) -> str:
        """ç”ŸæˆYouTubeè§†é¢‘ä¸“ç”¨Markdownæ ¼å¼
        
        Args:
            content_data: å†…å®¹æ•°æ®
            icon: ç±»å‹å›¾æ ‡
            type_name: ç±»å‹æ˜¾ç¤ºåç§°
            
        Returns:
            YouTubeæ ¼å¼çš„Markdown
        """
        # å¤„ç†æ—¶é—´æ ¼å¼åŒ–
        formatted_time = self._format_time(content_data.get('processed_time'))
        
        # æå–YouTubeç‰¹æœ‰ä¿¡æ¯
        source_url = content_data.get('source_url', '')
        video_title = content_data.get('video_title', content_data.get('title', ''))
        channel_name = content_data.get('channel_name', '')
        video_duration = content_data.get('video_duration', content_data.get('audio_duration', ''))
        view_count = content_data.get('view_count', '')
        
        markdown = f"""# {icon} {video_title}

**å†…å®¹ç±»å‹**: {type_name}  
**å¤„ç†æ—¶é—´**: {formatted_time}  
**åŸå§‹è§†é¢‘**: `{content_data.get('original_file', 'æœªçŸ¥')}`  
**è§†é¢‘é“¾æ¥**: {source_url if source_url else 'æœªæä¾›'}  
**é¢‘é“åç§°**: {channel_name if channel_name else 'æœªçŸ¥'}  
**è§†é¢‘æ—¶é•¿**: {video_duration if video_duration else 'æœªçŸ¥'}  
**è§‚çœ‹æ¬¡æ•°**: {view_count if view_count else 'æœªçŸ¥'}  
**å¤„ç†çŠ¶æ€**: âœ… å®Œæˆ

---

## ğŸ“¹ è§†é¢‘ä¿¡æ¯

{self._format_video_metadata(content_data)}

---

## ğŸ“„ å†…å®¹æ‘˜è¦

{self._clean_text(content_data.get('summary', ''))[:2000]}

---

## ğŸ§  çŸ¥è¯†æå–

{self._format_mindmap(content_data.get('mindmap', ''))}

---

## ğŸ·ï¸ å†…å®¹æ ‡ç­¾

{self._format_content_tags(content_data)}

---

## ğŸ“Š å¤„ç†ç»Ÿè®¡

{self._generate_statistics(content_data)}

---

<div class="footer youtube-footer">
<p><em>ğŸ“º YouTubeè§†é¢‘ç”± <a href="https://github.com/project-bach">Project Bach</a> æ™ºèƒ½åˆ†æ</em></p>
<p><small>åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</small></p>
</div>
"""
        return markdown
    
    def _generate_rss_markdown(self, content_data: Dict[str, Any], icon: str, type_name: str) -> str:
        """ç”ŸæˆRSSæ–‡ç« ä¸“ç”¨Markdownæ ¼å¼"""
        formatted_time = self._format_time(content_data.get('processed_time'))
        
        # RSSç‰¹æœ‰ä¿¡æ¯
        source_url = content_data.get('source_url', '')
        author = content_data.get('author', '')
        published_date = content_data.get('published_date', '')
        category = content_data.get('category', '')
        
        markdown = f"""# {icon} {content_data.get('title', 'æœªçŸ¥æ ‡é¢˜')}

**å†…å®¹ç±»å‹**: {type_name}  
**å¤„ç†æ—¶é—´**: {formatted_time}  
**åŸå§‹æ–‡ç« **: `{content_data.get('original_file', 'æœªçŸ¥')}`  
**æ–‡ç« é“¾æ¥**: {source_url if source_url else 'æœªæä¾›'}  
**ä½œè€…**: {author if author else 'æœªçŸ¥'}  
**å‘å¸ƒæ—¥æœŸ**: {published_date if published_date else 'æœªçŸ¥'}  
**åˆ†ç±»**: {category if category else 'æœªåˆ†ç±»'}  
**å¤„ç†çŠ¶æ€**: âœ… å®Œæˆ

---

## ğŸ“° æ–‡ç« æ‘˜è¦

{self._clean_text(content_data.get('summary', ''))[:2000]}

---

## ğŸ” å…³é”®ä¿¡æ¯æå–

{self._format_mindmap(content_data.get('mindmap', ''))}

---

## ğŸ·ï¸ æ–‡ç« æ ‡ç­¾

{self._format_content_tags(content_data)}

---

## ğŸ“Š å¤„ç†ç»Ÿè®¡

{self._generate_statistics(content_data)}

---

<div class="footer rss-footer">
<p><em>ğŸ“° RSSæ–‡ç« ç”± <a href="https://github.com/project-bach">Project Bach</a> æ™ºèƒ½åˆ†æ</em></p>
<p><small>åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</small></p>
</div>
"""
        return markdown
    
    def _generate_podcast_markdown(self, content_data: Dict[str, Any], icon: str, type_name: str) -> str:
        """ç”Ÿæˆæ’­å®¢ä¸“ç”¨Markdownæ ¼å¼"""
        formatted_time = self._format_time(content_data.get('processed_time'))
        
        # æ’­å®¢ç‰¹æœ‰ä¿¡æ¯
        episode_number = content_data.get('episode_number', '')
        host_name = content_data.get('host_name', '')
        guest_names = content_data.get('guest_names', [])
        podcast_series = content_data.get('podcast_series', '')
        
        markdown = f"""# {icon} {content_data.get('title', 'æœªçŸ¥æ ‡é¢˜')}

**å†…å®¹ç±»å‹**: {type_name}  
**å¤„ç†æ—¶é—´**: {formatted_time}  
**åŸå§‹æ–‡ä»¶**: `{content_data.get('original_file', 'æœªçŸ¥')}`  
**æ’­å®¢ç³»åˆ—**: {podcast_series if podcast_series else 'æœªçŸ¥'}  
**é›†æ•°**: {episode_number if episode_number else 'æœªçŸ¥'}  
**ä¸»æŒäºº**: {host_name if host_name else 'æœªçŸ¥'}  
**å˜‰å®¾**: {', '.join(guest_names) if guest_names else 'æ— '}  
**éŸ³é¢‘æ—¶é•¿**: {content_data.get('audio_duration', 'æœªçŸ¥')}  
**å¤„ç†çŠ¶æ€**: âœ… å®Œæˆ

---

## ğŸ™ï¸ èŠ‚ç›®æ‘˜è¦

{self._clean_text(content_data.get('summary', ''))[:2000]}

---

## ğŸ’¬ å¯¹è¯è¦ç‚¹

{self._format_mindmap(content_data.get('mindmap', ''))}

---

## ğŸ‘¥ äººç‰©ä¿¡æ¯

{self._format_anonymization_info(content_data.get('anonymized_names', {}))}

---

## ğŸ·ï¸ è¯é¢˜æ ‡ç­¾

{self._format_content_tags(content_data)}

---

## ğŸ“Š å¤„ç†ç»Ÿè®¡

{self._generate_statistics(content_data)}

---

<div class="footer podcast-footer">
<p><em>ğŸ™ï¸ æ’­å®¢å†…å®¹ç”± <a href="https://github.com/project-bach">Project Bach</a> æ™ºèƒ½åˆ†æ</em></p>
<p><small>åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</small></p>
</div>
"""
        return markdown
    
    def _generate_lecture_markdown(self, content_data: Dict[str, Any], icon: str, type_name: str) -> str:
        """ç”Ÿæˆå­¦æœ¯è®²åº§ä¸“ç”¨Markdownæ ¼å¼"""
        formatted_time = self._format_time(content_data.get('processed_time'))
        
        # è®²åº§ç‰¹æœ‰ä¿¡æ¯
        lecturer = content_data.get('lecturer', '')
        institution = content_data.get('institution', '')
        course_name = content_data.get('course_name', '')
        academic_field = content_data.get('academic_field', '')
        
        markdown = f"""# {icon} {content_data.get('title', 'æœªçŸ¥æ ‡é¢˜')}

**å†…å®¹ç±»å‹**: {type_name}  
**å¤„ç†æ—¶é—´**: {formatted_time}  
**åŸå§‹æ–‡ä»¶**: `{content_data.get('original_file', 'æœªçŸ¥')}`  
**è®²å¸ˆ**: {lecturer if lecturer else 'æœªçŸ¥'}  
**æœºæ„**: {institution if institution else 'æœªçŸ¥'}  
**è¯¾ç¨‹åç§°**: {course_name if course_name else 'æœªçŸ¥'}  
**å­¦ç§‘é¢†åŸŸ**: {academic_field if academic_field else 'æœªçŸ¥'}  
**è®²åº§æ—¶é•¿**: {content_data.get('audio_duration', 'æœªçŸ¥')}  
**å¤„ç†çŠ¶æ€**: âœ… å®Œæˆ

---

## ğŸ“š è®²åº§æ‘˜è¦

{self._clean_text(content_data.get('summary', ''))[:2000]}

---

## ğŸ§  çŸ¥è¯†æ¡†æ¶

{self._format_mindmap(content_data.get('mindmap', ''))}

---

## ğŸ‘¥ äººåå¤„ç†

{self._format_anonymization_info(content_data.get('anonymized_names', {}))}

---

## ğŸ”¬ å­¦æœ¯æ ‡ç­¾

{self._format_content_tags(content_data)}

---

## ğŸ“Š å¤„ç†ç»Ÿè®¡

{self._generate_statistics(content_data)}

---

<div class="footer lecture-footer">
<p><em>ğŸ“ å­¦æœ¯è®²åº§ç”± <a href="https://github.com/project-bach">Project Bach</a> æ™ºèƒ½åˆ†æ</em></p>
<p><small>åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</small></p>
</div>
"""
        return markdown
    
    def _generate_generic_markdown(self, content_data: Dict[str, Any], icon: str, type_name: str) -> str:
        """ç”Ÿæˆé€šç”¨Markdownæ ¼å¼ï¼ˆå…¼å®¹åŸæœ‰æ ¼å¼ï¼‰"""
        return self._generate_markdown_content(content_data)
    
    def _format_time(self, timestamp: Any) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æˆ³
        
        Args:
            timestamp: æ—¶é—´æˆ³
            
        Returns:
            æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²
        """
        if not timestamp:
            return datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')
        
        if isinstance(timestamp, str):
            try:
                dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                return dt.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')
            except:
                return str(timestamp)
        else:
            return str(timestamp)
    
    def _format_video_metadata(self, content_data: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–è§†é¢‘å…ƒæ•°æ®"""
        metadata_items = []
        
        if content_data.get('video_description'):
            metadata_items.append(f"**è§†é¢‘æè¿°**: {content_data['video_description'][:300]}...")
        
        if content_data.get('upload_date'):
            metadata_items.append(f"**ä¸Šä¼ æ—¥æœŸ**: {content_data['upload_date']}")
        
        if content_data.get('video_tags'):
            tags = content_data['video_tags']
            if isinstance(tags, list):
                metadata_items.append(f"**åŸå§‹æ ‡ç­¾**: {', '.join(tags[:10])}")
        
        return '\n'.join(metadata_items) if metadata_items else 'æš‚æ— è¯¦ç»†è§†é¢‘ä¿¡æ¯'
    
    def _format_content_tags(self, content_data: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–å†…å®¹æ ‡ç­¾"""
        # ä¼˜å…ˆä½¿ç”¨åˆ†ç±»ç»“æœä¸­çš„æ ‡ç­¾
        if 'classification_result' in content_data:
            classification = content_data['classification_result']
            if isinstance(classification, dict) and 'tags' in classification:
                tags = classification['tags']
                if tags:
                    return '`' + '` `'.join(tags) + '`'
        
        # å›é€€åˆ°å…¶ä»–æ ‡ç­¾æ¥æº
        if 'extracted_tags' in content_data:
            tags = content_data['extracted_tags']
            if tags:
                return '`' + '` `'.join(tags) + '`'
        
        return 'æš‚æ— è‡ªåŠ¨æå–çš„æ ‡ç­¾'
    
    def _generate_markdown_content(self, content_data: Dict[str, Any]) -> str:
        """ç”ŸæˆMarkdownå†…å®¹
        
        Args:
            content_data: åŸå§‹å†…å®¹æ•°æ®
            
        Returns:
            Markdownæ ¼å¼å†…å®¹
        """
        # å¤„ç†æ—¶é—´æ ¼å¼åŒ–
        processed_time = content_data.get('processed_time', datetime.now().isoformat())
        if isinstance(processed_time, str):
            try:
                dt = datetime.fromisoformat(processed_time.replace('Z', '+00:00'))
                formatted_time = dt.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')
            except:
                formatted_time = processed_time
        else:
            formatted_time = str(processed_time)
        
        # æ„å»ºMarkdownå†…å®¹
        markdown_content = f"""# {content_data['title']}

**å¤„ç†æ—¶é—´**: {formatted_time}  
**åŸå§‹æ–‡ä»¶**: `{content_data.get('original_file', 'æœªçŸ¥')}`  
**å¤„ç†çŠ¶æ€**: âœ… å®Œæˆ

---

## ğŸ“„ å†…å®¹æ‘˜è¦

{self._clean_text(content_data.get('summary', ''))[:2000]}

---

## ğŸ§  æ€ç»´å¯¼å›¾

{self._format_mindmap(content_data.get('mindmap', ''))}

---

## ğŸ”’ äººååŒ¿ååŒ–ä¿¡æ¯

{self._format_anonymization_info(content_data.get('anonymized_names', {}))}

---

## ğŸ“Š å¤„ç†ç»Ÿè®¡

{self._generate_statistics(content_data)}

---

<div class="footer">
<p><em>ç”± <a href="https://github.com/project-bach">Project Bach</a> è‡ªåŠ¨ç”Ÿæˆ</em></p>
<p><small>ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</small></p>
</div>
"""
        
        return markdown_content
    
    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬å†…å®¹
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        if not text:
            return "æš‚æ— å†…å®¹"
        
        # ç§»é™¤å¤šä½™çš„ç©ºç™½è¡Œ
        text = re.sub(r'\n\s*\n', '\n\n', text.strip())
        
        # è½¬ä¹‰HTMLç‰¹æ®Šå­—ç¬¦
        text = html.escape(text)
        
        # è¿˜åŸMarkdownè¯­æ³•
        text = text.replace('&gt;', '>')
        text = text.replace('&lt;', '<')
        text = text.replace('&#x27;', "'")
        
        return text
    
    def _format_mindmap(self, mindmap_text: str) -> str:
        """æ ¼å¼åŒ–æ€ç»´å¯¼å›¾å†…å®¹
        
        Args:
            mindmap_text: æ€ç»´å¯¼å›¾æ–‡æœ¬
            
        Returns:
            æ ¼å¼åŒ–åçš„æ€ç»´å¯¼å›¾
        """
        if not mindmap_text:
            return "æš‚æœªç”Ÿæˆæ€ç»´å¯¼å›¾"
        
        # ç¡®ä¿æ€ç»´å¯¼å›¾æ ¼å¼æ­£ç¡®
        if not mindmap_text.strip().startswith('#'):
            # å¦‚æœä¸æ˜¯æ ‡å‡†Markdownæ ¼å¼ï¼Œè¿›è¡ŒåŸºç¡€æ ¼å¼åŒ–
            lines = mindmap_text.strip().split('\n')
            formatted_lines = []
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                # ç®€å•çš„å±‚çº§è¯†åˆ«
                if line.startswith('- '):
                    formatted_lines.append(line)
                elif line.startswith('  - '):
                    formatted_lines.append(line)
                elif ':' in line:
                    formatted_lines.append(f"## {line}")
                else:
                    formatted_lines.append(f"- {line}")
            
            return '\n'.join(formatted_lines)
        
        return self._clean_text(mindmap_text)
    
    def _format_anonymization_info(self, anonymized_names: Dict[str, str]) -> str:
        """æ ¼å¼åŒ–äººååŒ¿ååŒ–ä¿¡æ¯
        
        Args:
            anonymized_names: äººåæ˜ å°„å­—å…¸
            
        Returns:
            æ ¼å¼åŒ–åçš„åŒ¿ååŒ–ä¿¡æ¯
        """
        if not anonymized_names:
            return "æœ¬æ¬¡å¤„ç†æœªæ£€æµ‹åˆ°éœ€è¦åŒ¿ååŒ–çš„äººå"
        
        info = f"æœ¬æ¬¡å¤„ç†ä¸­å…±åŒ¿ååŒ–äº† **{len(anonymized_names)}** ä¸ªäººå:\n\n"
        info += "| åºå· | åŒ¿ååŒ–å | æ£€æµ‹ç±»å‹ |\n"
        info += "|------|----------|----------|\n"
        
        for idx, (original, anonymous) in enumerate(anonymized_names.items(), 1):
            # åˆ¤æ–­æ˜¯ä¸­æ–‡è¿˜æ˜¯è‹±æ–‡å
            name_type = "ä¸­æ–‡" if any('\u4e00' <= char <= '\u9fff' for char in original) else "è‹±æ–‡"
            info += f"| {idx} | {anonymous} | {name_type} |\n"
        
        info += "\n> ğŸ’¡ ä¸ºä¿æŠ¤éšç§ï¼Œæ‰€æœ‰äººåå·²è¢«æ›¿æ¢ä¸ºè™šæ‹Ÿå§“å"
        
        return info
    
    def _generate_statistics(self, content_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¤„ç†ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            content_data: å†…å®¹æ•°æ®
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯Markdown
        """
        # è®¡ç®—å„ç§ç»Ÿè®¡æŒ‡æ ‡
        summary_length = len(content_data.get('summary', ''))
        mindmap_length = len(content_data.get('mindmap', ''))
        anonymized_count = len(content_data.get('anonymized_names', {}))
        
        # ä¼°ç®—å¤„ç†æ—¶é—´
        processing_time = content_data.get('processing_duration', 'æœªçŸ¥')
        
        stats = f"""| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ‘˜è¦é•¿åº¦ | {summary_length} å­—ç¬¦ |
| æ€ç»´å¯¼å›¾é•¿åº¦ | {mindmap_length} å­—ç¬¦ |
| åŒ¿ååŒ–äººåæ•° | {anonymized_count} ä¸ª |
| å¤„ç†æ—¶é•¿ | {processing_time} |
| æ–‡ä»¶å¤§å° | {content_data.get('file_size', 'æœªçŸ¥')} |
| éŸ³é¢‘æ—¶é•¿ | {content_data.get('audio_duration', 'æœªçŸ¥')} |
"""
        
        return stats
    
    def _extract_metadata(self, content_data: Dict[str, Any]) -> Dict[str, Any]:
        """æå–å†…å®¹å…ƒæ•°æ®
        
        Phase 6 å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒå¤šåª’ä½“å†…å®¹ç±»å‹çš„ä¸“é—¨å…ƒæ•°æ®
        
        Args:
            content_data: å†…å®¹æ•°æ®
            
        Returns:
            å…ƒæ•°æ®å­—å…¸
        """
        # æ£€æµ‹å†…å®¹ç±»å‹
        content_type = self._detect_content_type(content_data)
        type_config = self.content_types_config.get(content_type, {})
        
        # åŸºç¡€å…ƒæ•°æ®
        metadata = {
            'title': content_data['title'],
            'description': content_data.get('summary', '')[:200] + '...' if len(content_data.get('summary', '')) > 200 else content_data.get('summary', ''),
            'keywords': self._extract_enhanced_keywords(content_data, content_type),
            'author': 'Project Bach',
            'created': content_data.get('processed_time', datetime.now().isoformat()),
            'language': 'zh-CN',
            'type': f'{content_type}-analysis',
            'content_type': content_type,
            'content_type_display': type_config.get('display_name', content_type.title()),
            'content_type_icon': type_config.get('icon', 'ğŸ“„')
        }
        
        # ç±»å‹ç‰¹å®šçš„å…ƒæ•°æ®
        if content_type == 'youtube':
            metadata.update({
                'source_platform': 'YouTube',
                'video_url': content_data.get('source_url', ''),
                'channel': content_data.get('channel_name', ''),
                'video_duration': content_data.get('video_duration', content_data.get('audio_duration', '')),
                'view_count': content_data.get('view_count', '')
            })
        elif content_type == 'rss':
            metadata.update({
                'source_platform': 'RSS',
                'article_url': content_data.get('source_url', ''),
                'article_author': content_data.get('author', ''),
                'published_date': content_data.get('published_date', ''),
                'category': content_data.get('category', '')
            })
        elif content_type == 'podcast':
            metadata.update({
                'source_platform': 'Podcast',
                'episode_number': content_data.get('episode_number', ''),
                'host': content_data.get('host_name', ''),
                'guests': content_data.get('guest_names', []),
                'series': content_data.get('podcast_series', ''),
                'duration': content_data.get('audio_duration', '')
            })
        elif content_type == 'lecture':
            metadata.update({
                'source_platform': 'Academic',
                'lecturer': content_data.get('lecturer', ''),
                'institution': content_data.get('institution', ''),
                'course': content_data.get('course_name', ''),
                'field': content_data.get('academic_field', ''),
                'duration': content_data.get('audio_duration', '')
            })
        
        # æ·»åŠ åˆ†ç±»ç»“æœä¿¡æ¯
        if 'classification_result' in content_data:
            classification = content_data['classification_result']
            if isinstance(classification, dict):
                metadata.update({
                    'auto_detected': classification.get('auto_detected', True),
                    'classification_confidence': classification.get('confidence', 0.0),
                    'extracted_tags': classification.get('tags', [])
                })
        
        return metadata
    
    def _extract_keywords(self, content_data: Dict[str, Any]) -> List[str]:
        """æå–å…³é”®è¯ï¼ˆå…¼å®¹ç‰ˆæœ¬ï¼‰
        
        Args:
            content_data: å†…å®¹æ•°æ®
            
        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        return self._extract_enhanced_keywords(content_data, 'lecture')
    
    def _extract_enhanced_keywords(self, content_data: Dict[str, Any], content_type: str) -> List[str]:
        """æå–å¢å¼ºå…³é”®è¯
        
        Phase 6 ç‰ˆæœ¬ï¼Œæ ¹æ®å†…å®¹ç±»å‹æå–ä¸“é—¨å…³é”®è¯
        
        Args:
            content_data: å†…å®¹æ•°æ®
            content_type: å†…å®¹ç±»å‹
            
        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        # åŸºç¡€å…³é”®è¯
        keywords = ['å¤šåª’ä½“å¤„ç†', 'AIåˆ†æ', 'å†…å®¹æ‘˜è¦']
        
        # æ ¹æ®å†…å®¹ç±»å‹æ·»åŠ ç‰¹å®šå…³é”®è¯
        if content_type == 'youtube':
            keywords.extend(['YouTube', 'è§†é¢‘å¤„ç†', 'åœ¨çº¿å†…å®¹', 'æ•™å­¦è§†é¢‘'])
        elif content_type == 'rss':
            keywords.extend(['RSSè®¢é˜…', 'æ–‡ç« åˆ†æ', 'æ–°é—»å¤„ç†', 'åšå®¢å†…å®¹'])
        elif content_type == 'podcast':
            keywords.extend(['æ’­å®¢', 'éŸ³é¢‘èŠ‚ç›®', 'è®¿è°ˆå†…å®¹', 'å¯¹è¯åˆ†æ'])
        elif content_type == 'lecture':
            keywords.extend(['å­¦æœ¯è®²åº§', 'æ•™è‚²å†…å®¹', 'è¯¾ç¨‹å½•éŸ³', 'çŸ¥è¯†ä¼ æ’­'])
        
        # ä»æ ‡é¢˜æå–
        title = content_data.get('title', '')
        title_keywords = {
            'ä¼šè®®': 'ä¼šè®®',
            'è®²åº§': 'è®²åº§',
            'åŸ¹è®­': 'åŸ¹è®­',
            'è¯¾ç¨‹': 'è¯¾ç¨‹',
            'æ•™ç¨‹': 'æ•™ç¨‹',
            'è®¿è°ˆ': 'è®¿è°ˆ',
            'å¯¹è¯': 'å¯¹è¯',
            'æ–°é—»': 'æ–°é—»',
            'æŠ€æœ¯': 'æŠ€æœ¯åˆ†äº«',
            'ç§‘å­¦': 'ç§‘å­¦ç ”ç©¶',
            'åŒ»å­¦': 'åŒ»å­¦å†…å®¹',
            'å•†ä¸š': 'å•†ä¸šåˆ†æ',
            'ç»æµ': 'ç»æµè®¨è®º',
            'AI': 'äººå·¥æ™ºèƒ½',
            'æœºå™¨å­¦ä¹ ': 'æœºå™¨å­¦ä¹ ',
            'æ•°æ®': 'æ•°æ®åˆ†æ'
        }
        
        for term, keyword in title_keywords.items():
            if term in title:
                keywords.append(keyword)
        
        # ä»æ‘˜è¦æå–ä¸“ä¸šè¯æ±‡
        summary = content_data.get('summary', '')
        summary_keywords = {
            'é¡¹ç›®': 'é¡¹ç›®ç®¡ç†',
            'æŠ€æœ¯': 'æŠ€æœ¯è®¨è®º',
            'å†³ç­–': 'å†³ç­–åˆ†æ',
            'ç ”ç©¶': 'å­¦æœ¯ç ”ç©¶',
            'å¼€å‘': 'è½¯ä»¶å¼€å‘',
            'è®¾è®¡': 'è®¾è®¡æ€ç»´',
            'åˆ›æ–°': 'åˆ›æ–°ç†å¿µ',
            'äº§å“': 'äº§å“ç®¡ç†',
            'å¸‚åœº': 'å¸‚åœºåˆ†æ',
            'ç”¨æˆ·': 'ç”¨æˆ·ä½“éªŒ',
            'æ•°æ®': 'æ•°æ®ç§‘å­¦',
            'ç®—æ³•': 'ç®—æ³•åˆ†æ',
            'ç³»ç»Ÿ': 'ç³»ç»Ÿè®¾è®¡',
            'æ¶æ„': 'æŠ€æœ¯æ¶æ„',
            'å®‰å…¨': 'ç½‘ç»œå®‰å…¨',
            'äº‘è®¡ç®—': 'äº‘è®¡ç®—',
            'åŒºå—é“¾': 'åŒºå—é“¾',
            'ç‰©è”ç½‘': 'ç‰©è”ç½‘',
            'å¤§æ•°æ®': 'å¤§æ•°æ®',
            'æ·±åº¦å­¦ä¹ ': 'æ·±åº¦å­¦ä¹ '
        }
        
        for term, keyword in summary_keywords.items():
            if term in summary:
                keywords.append(keyword)
        
        # ä»åˆ†ç±»ç»“æœè·å–æ ‡ç­¾
        if 'classification_result' in content_data:
            classification = content_data['classification_result']
            if isinstance(classification, dict) and 'tags' in classification:
                classification_tags = classification['tags']
                if isinstance(classification_tags, list):
                    keywords.extend(classification_tags[:5])  # æœ€å¤šæ·»åŠ 5ä¸ªåˆ†ç±»æ ‡ç­¾
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        unique_keywords = list(set(keywords))
        return unique_keywords[:15]  # æœ€å¤šè¿”å›15ä¸ªå…³é”®è¯
    
    def _generate_filename(self, content_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ–‡ä»¶å
        
        Args:
            content_data: å†…å®¹æ•°æ®
            
        Returns:
            å®‰å…¨çš„æ–‡ä»¶å
        """
        # åŸºäºåŸå§‹æ–‡ä»¶åç”Ÿæˆ
        original_file = content_data.get('original_file', 'unknown')
        
        # ç§»é™¤æ‰©å±•å
        base_name = Path(original_file).stem
        
        # æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦
        safe_name = re.sub(r'[^\w\-_\u4e00-\u9fff]', '_', base_name)
        
        # æ·»åŠ æ—¶é—´æˆ³é¿å…å†²çª
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        return f"{safe_name}_{timestamp}.html"
    
    def generate_html_from_markdown(self, markdown_content: str) -> str:
        """å°†Markdownè½¬æ¢ä¸ºHTML
        
        Args:
            markdown_content: Markdownå†…å®¹
            
        Returns:
            HTMLå†…å®¹
        """
        try:
            # é‡ç½®Markdownå¤„ç†å™¨çŠ¶æ€
            self.md_processor.reset()
            
            # è½¬æ¢ä¸ºHTML
            html_content = self.md_processor.convert(markdown_content)
            
            # æ·»åŠ é¢å¤–çš„CSSç±»
            html_content = self._enhance_html(html_content)
            
            return html_content
            
        except Exception as e:
            self.logger.error(f"Markdownè½¬HTMLå¤±è´¥: {str(e)}")
            # è¿”å›åŸºç¡€HTML
            return f"""<div class="error">
                <h2>å†…å®¹è½¬æ¢å¤±è´¥</h2>
                <p>æ— æ³•å°†Markdownå†…å®¹è½¬æ¢ä¸ºHTMLæ ¼å¼ã€‚</p>
                <pre>{html.escape(markdown_content)}</pre>
            </div>"""
    
    def _enhance_html(self, html_content: str) -> str:
        """å¢å¼ºHTMLå†…å®¹
        
        Args:
            html_content: åŸºç¡€HTML
            
        Returns:
            å¢å¼ºåçš„HTML
        """
        # ä¸ºè¡¨æ ¼æ·»åŠ CSSç±»
        html_content = re.sub(r'<table>', '<table class="table table-striped">', html_content)
        
        # ä¸ºä»£ç å—æ·»åŠ CSSç±»
        html_content = re.sub(r'<pre>', '<pre class="code-block">', html_content)
        
        # ä¸ºå¼•ç”¨æ·»åŠ CSSç±»
        html_content = re.sub(r'<blockquote>', '<blockquote class="quote">', html_content)
        
        # ä¸ºé“¾æ¥æ·»åŠ target="_blank"
        html_content = re.sub(r'<a href="http', '<a target="_blank" href="http', html_content)
        
        return html_content
    
    def create_site_index(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ›å»ºç½‘ç«™é¦–é¡µç´¢å¼•
        
        Phase 6 å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒå†…å®¹ç±»å‹åˆ†ç±»æ˜¾ç¤º
        
        Args:
            results: æ‰€æœ‰å¤„ç†ç»“æœåˆ—è¡¨
            
        Returns:
            ç´¢å¼•é¡µé¢å†…å®¹
        """
        self.logger.info(f"åˆ›å»ºPhase 6ç½‘ç«™ç´¢å¼•ï¼ŒåŒ…å«{len(results)}ä¸ªç»“æœ")
        
        try:
            # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            sorted_results = sorted(
                results, 
                key=lambda x: x.get('date', ''), 
                reverse=True
            )
            
            # æŒ‰å†…å®¹ç±»å‹åˆ†ç»„ç»Ÿè®¡
            type_stats = self._analyze_content_types(sorted_results)
            
            # ç”Ÿæˆç´¢å¼•Markdown
            index_markdown = self._generate_enhanced_index_markdown(sorted_results, type_stats)
            
            # è½¬æ¢ä¸ºHTML
            index_html = self.generate_html_from_markdown(index_markdown)
            
            # ç”Ÿæˆå…ƒæ•°æ®
            metadata = {
                'title': 'Project Bach - å¤šåª’ä½“å†…å®¹å¤„ç†ç»“æœ',
                'description': f'å…±æ”¶å½•{len(results)}ä¸ªå¤šåª’ä½“å†…å®¹å¤„ç†ç»“æœï¼ŒåŒ…å«{len(type_stats)}ç§å†…å®¹ç±»å‹',
                'keywords': ['å¤šåª’ä½“å¤„ç†', 'AIåˆ†æ', 'å†…å®¹åˆ†ç±»', 'ç»“æœç´¢å¼•'] + list(type_stats.keys()),
                'author': 'Project Bach',
                'created': datetime.now().isoformat(),
                'language': 'zh-CN',
                'type': 'index'
            }
            
            return {
                'success': True,
                'content': {
                    'markdown': index_markdown,
                    'html': index_html,
                    'metadata': metadata,
                    'filename': 'index.html',
                    'title': 'Project Bach - å¤šåª’ä½“å†…å®¹å¤„ç†ç»“æœ',
                    'total_items': len(results),
                    'content_type_stats': type_stats
                }
            }
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºç´¢å¼•å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _analyze_content_types(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æå†…å®¹ç±»å‹ç»Ÿè®¡
        
        Args:
            results: å¤„ç†ç»“æœåˆ—è¡¨
            
        Returns:
            å†…å®¹ç±»å‹ç»Ÿè®¡å­—å…¸
        """
        type_stats = {}
        
        for result in results:
            # å°è¯•ä»ä¸åŒå­—æ®µè·å–å†…å®¹ç±»å‹
            content_type = None
            
            # ä¼˜å…ˆçº§1: content_typeå­—æ®µ
            if 'content_type' in result:
                content_type = result['content_type']
            # ä¼˜å…ˆçº§2: classification_resultä¸­çš„content_type
            elif 'classification_result' in result:
                classification = result['classification_result']
                if isinstance(classification, dict) and 'content_type' in classification:
                    content_type = classification['content_type']
            # ä¼˜å…ˆçº§3: ä»æ–‡ä»¶åæ¨æ–­
            elif 'file' in result or 'original_file' in result:
                filename = result.get('file', result.get('original_file', '')).lower()
                content_type = self._infer_type_from_filename(filename)
            
            # é»˜è®¤ä¸ºlecture
            if not content_type:
                content_type = 'lecture'
            
            # ç»Ÿè®¡
            if content_type not in type_stats:
                type_config = self.content_types_config.get(content_type, {})
                type_stats[content_type] = {
                    'count': 0,
                    'icon': type_config.get('icon', 'ğŸ“„'),
                    'display_name': type_config.get('display_name', content_type.title()),
                    'description': type_config.get('description', ''),
                    'recent_items': []
                }
            
            type_stats[content_type]['count'] += 1
            
            # è®°å½•æœ€è¿‘çš„æ¡ç›®ï¼ˆæœ€å¤š5ä¸ªï¼‰
            if len(type_stats[content_type]['recent_items']) < 5:
                type_stats[content_type]['recent_items'].append({
                    'title': result.get('title', 'æœªçŸ¥æ ‡é¢˜')[:30],
                    'date': result.get('date', ''),
                    'file': result.get('file', '#')
                })
        
        return type_stats
    
    def _infer_type_from_filename(self, filename: str) -> str:
        """ä»æ–‡ä»¶åæ¨æ–­å†…å®¹ç±»å‹"""
        if any(keyword in filename for keyword in ['youtube', 'video', 'tutorial']):
            return 'youtube'
        elif any(keyword in filename for keyword in ['rss', 'feed', 'article', 'news']):
            return 'rss'
        elif any(keyword in filename for keyword in ['podcast', 'interview', 'talk']):
            return 'podcast'
        elif any(keyword in filename for keyword in ['lecture', 'course', 'professor', 'class']):
            return 'lecture'
        else:
            return 'lecture'
    
    def _generate_enhanced_index_markdown(self, results: List[Dict[str, Any]], type_stats: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¢å¼ºçš„ç´¢å¼•é¡µé¢Markdown
        
        Args:
            results: ç»“æœåˆ—è¡¨
            type_stats: å†…å®¹ç±»å‹ç»Ÿè®¡
            
        Returns:
            å¢å¼ºçš„ç´¢å¼•Markdownå†…å®¹
        """
        # é¡µé¢å¤´éƒ¨
        markdown = f"""# Project Bach å¤šåª’ä½“å†…å®¹å¤„ç†ç»“æœ

> ğŸµ æ™ºèƒ½å¤šåª’ä½“å†…å®¹å¤„ç†ä¸åˆ†æå¹³å°  
> ğŸ“Š **å…±æ”¶å½• {len(results)} ä¸ªå¤„ç†ç»“æœ**  
> ğŸ·ï¸ **åŒ…å« {len(type_stats)} ç§å†…å®¹ç±»å‹**

---

## ğŸ“‹ å†…å®¹ç±»å‹æ¦‚è§ˆ

"""
        
        # å†…å®¹ç±»å‹ç»Ÿè®¡å¡ç‰‡
        for content_type, stats in type_stats.items():
            icon = stats['icon']
            name = stats['display_name']
            count = stats['count']
            description = stats['description']
            
            markdown += f"""### {icon} {name} ({count}ä¸ª)

{description}

"""
            
            # æ˜¾ç¤ºæœ€è¿‘çš„æ¡ç›®
            if stats['recent_items']:
                markdown += "**æœ€æ–°å†…å®¹**:\n"
                for item in stats['recent_items']:
                    markdown += f"- [{item['title']}]({item['file']}) - {item['date']}\n"
                markdown += "\n"
        
        markdown += "---\n\n"
        
        # æœ€æ–°ç»“æœè¡¨æ ¼
        markdown += """## ğŸ“‹ æœ€æ–°ç»“æœ

"""
        
        if not results:
            markdown += "æš‚æ— å¤„ç†ç»“æœã€‚\n"
        else:
            # ç»“æœè¡¨æ ¼ï¼ˆå¢åŠ ç±»å‹åˆ—ï¼‰
            markdown += """| ç±»å‹ | æ—¥æœŸ | æ ‡é¢˜ | æ‘˜è¦é¢„è§ˆ | æ“ä½œ |
|------|------|------|----------|------|
"""
            
            for result in results[:20]:  # åªæ˜¾ç¤ºæœ€æ–°20ä¸ª
                # è·å–å†…å®¹ç±»å‹å›¾æ ‡
                content_type = result.get('content_type', 'lecture')
                type_icon = type_stats.get(content_type, {}).get('icon', 'ğŸ“„')
                
                title = result.get('title', 'æœªçŸ¥æ ‡é¢˜')[:30]
                date = result.get('date', 'æœªçŸ¥æ—¥æœŸ')
                preview = result.get('summary', 'æš‚æ— æ‘˜è¦')[:50] + '...' if len(result.get('summary', '')) > 50 else result.get('summary', 'æš‚æ— æ‘˜è¦')
                filename = result.get('file', '#')
                
                markdown += f"| {type_icon} | {date} | [{title}]({filename}) | {preview} | [æŸ¥çœ‹è¯¦æƒ…]({filename}) |\n"
            
            # å¦‚æœç»“æœå¤ªå¤šï¼Œæ˜¾ç¤ºæ›´å¤šé“¾æ¥
            if len(results) > 20:
                markdown += f"\n> ğŸ“‘ å…±{len(results)}ä¸ªç»“æœï¼Œä»…æ˜¾ç¤ºæœ€æ–°20ä¸ªã€‚[æŸ¥çœ‹å…¨éƒ¨ â†’](archive.html)\n"
        
        # ç»Ÿè®¡ä¿¡æ¯
        markdown += f"""

---

## ğŸ“Š ç»Ÿè®¡æ¦‚è§ˆ

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ€»å¤„ç†æ•° | {len(results)} |
| å†…å®¹ç±»å‹æ•° | {len(type_stats)} |
| æœ¬æœˆæ–°å¢ | {self._count_this_month(results)} |
| æœ¬å‘¨æ–°å¢ | {self._count_this_week(results)} |
| æœ€åæ›´æ–° | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} |

### ğŸ·ï¸ ç±»å‹åˆ†å¸ƒ

"""
        
        # ç±»å‹åˆ†å¸ƒç»Ÿè®¡
        for content_type, stats in sorted(type_stats.items(), key=lambda x: x[1]['count'], reverse=True):
            percentage = (stats['count'] / len(results)) * 100
            markdown += f"- {stats['icon']} **{stats['display_name']}**: {stats['count']} ä¸ª ({percentage:.1f}%)\n"
        
        markdown += f"""

---

## ğŸ” å¿«é€Ÿå¯¼èˆª

### ğŸ“± æŒ‰å†…å®¹ç±»å‹æµè§ˆ
"""
        
        # æŒ‰ç±»å‹å¯¼èˆªé“¾æ¥
        for content_type, stats in type_stats.items():
            markdown += f"- [{stats['icon']} {stats['display_name']}](#{content_type}.html) - {stats['count']} ä¸ªå†…å®¹\n"
        
        markdown += f"""

### ğŸ› ï¸ åŠŸèƒ½é¡µé¢
- [ğŸ“ˆ æ•°æ®ç»Ÿè®¡](stats.html) - å¤„ç†ç»“æœç»Ÿè®¡åˆ†æ
- [ğŸ·ï¸ æ ‡ç­¾äº‘](tags.html) - å†…å®¹æ ‡ç­¾åˆ†ç±»
- [ğŸ” æœç´¢åŠŸèƒ½](search.html) - æœç´¢å¤„ç†ç»“æœ
- [â„¹ï¸ å…³äºé¡¹ç›®](about.html) - Project Bach ä»‹ç»

---

<div class="footer enhanced-footer">
<p><strong>Project Bach</strong> - æ™ºèƒ½å¤šåª’ä½“å†…å®¹å¤„ç†ä¸åˆ†æå¹³å°</p>
<p><em>æœ€åæ›´æ–°: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}</em></p>
<p>
    <a href="https://github.com/project-bach" target="_blank">ğŸ”— GitHub</a> | 
    <a href="mailto:contact@project-bach.com">ğŸ“§ è”ç³»æˆ‘ä»¬</a> |
    <span class="version">Phase 6 Enhanced</span>
</p>
</div>
"""
        
        return markdown
    
    def _generate_index_markdown(self, results: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆç´¢å¼•é¡µé¢Markdown
        
        Args:
            results: ç»“æœåˆ—è¡¨
            
        Returns:
            ç´¢å¼•Markdownå†…å®¹
        """
        # é¡µé¢å¤´éƒ¨
        markdown = f"""# Project Bach éŸ³é¢‘å¤„ç†ç»“æœ

> ğŸµ æ™ºèƒ½éŸ³é¢‘å¤„ç†ä¸å†…å®¹åˆ†æå¹³å°  
> ğŸ“Š **å…±æ”¶å½• {len(results)} ä¸ªå¤„ç†ç»“æœ**

---

## ğŸ“‹ æœ€æ–°ç»“æœ

"""
        
        if not results:
            markdown += "æš‚æ— å¤„ç†ç»“æœã€‚\n"
        else:
            # ç»“æœè¡¨æ ¼
            markdown += """| æ—¥æœŸ | æ ‡é¢˜ | æ‘˜è¦é¢„è§ˆ | æ“ä½œ |
|------|------|----------|------|
"""
            
            for result in results[:20]:  # åªæ˜¾ç¤ºæœ€æ–°20ä¸ª
                title = result.get('title', 'æœªçŸ¥æ ‡é¢˜')[:30]
                date = result.get('date', 'æœªçŸ¥æ—¥æœŸ')
                preview = result.get('summary', 'æš‚æ— æ‘˜è¦')[:50] + '...' if len(result.get('summary', '')) > 50 else result.get('summary', 'æš‚æ— æ‘˜è¦')
                filename = result.get('file', '#')
                
                markdown += f"| {date} | [{title}]({filename}) | {preview} | [æŸ¥çœ‹è¯¦æƒ…]({filename}) |\n"
            
            # å¦‚æœç»“æœå¤ªå¤šï¼Œæ˜¾ç¤ºæ›´å¤šé“¾æ¥
            if len(results) > 20:
                markdown += f"\n> ğŸ“‘ å…±{len(results)}ä¸ªç»“æœï¼Œä»…æ˜¾ç¤ºæœ€æ–°20ä¸ªã€‚[æŸ¥çœ‹å…¨éƒ¨ â†’](archive.html)\n"
        
        # ç»Ÿè®¡ä¿¡æ¯
        markdown += f"""

---

## ğŸ“Š ç»Ÿè®¡æ¦‚è§ˆ

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ€»å¤„ç†æ•° | {len(results)} |
| æœ¬æœˆæ–°å¢ | {self._count_this_month(results)} |
| æœ¬å‘¨æ–°å¢ | {self._count_this_week(results)} |
| æœ€åæ›´æ–° | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} |

---

## ğŸ” å¿«é€Ÿå¯¼èˆª

- [ğŸ“ˆ æ•°æ®ç»Ÿè®¡](stats.html) - å¤„ç†ç»“æœç»Ÿè®¡åˆ†æ
- [ğŸ·ï¸ æ ‡ç­¾äº‘](tags.html) - å†…å®¹æ ‡ç­¾åˆ†ç±»
- [ğŸ” æœç´¢åŠŸèƒ½](search.html) - æœç´¢å¤„ç†ç»“æœ
- [â„¹ï¸ å…³äºé¡¹ç›®](about.html) - Project Bach ä»‹ç»

---

<div class="footer">
<p><strong>Project Bach</strong> - AIéŸ³é¢‘å¤„ç†ä¸å†…å®¹åˆ†æ</p>
<p><em>æœ€åæ›´æ–°: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}</em></p>
<p><a href="https://github.com/project-bach" target="_blank">ğŸ”— GitHub</a> | <a href="mailto:contact@project-bach.com">ğŸ“§ è”ç³»æˆ‘ä»¬</a></p>
</div>
"""
        
        return markdown
    
    def _count_this_month(self, results: List[Dict[str, Any]]) -> int:
        """ç»Ÿè®¡æœ¬æœˆç»“æœæ•°"""
        current_month = datetime.now().strftime('%Y-%m')
        return sum(1 for r in results if r.get('date', '').startswith(current_month))
    
    def _count_this_week(self, results: List[Dict[str, Any]]) -> int:
        """ç»Ÿè®¡æœ¬å‘¨ç»“æœæ•°"""
        # ç®€å•å®ç°ï¼šæœ€è¿‘7å¤©
        week_ago = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
        return sum(1 for r in results if r.get('date', '') >= week_ago)
    
    def validate_content_structure(self, content: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯å†…å®¹ç»“æ„
        
        Args:
            content: å†…å®¹æ•°æ®
            
        Returns:
            éªŒè¯ç»“æœ
        """
        required_fields = ['title', 'summary', 'mindmap', 'processed_time']
        missing_fields = []
        empty_fields = []
        
        for field in required_fields:
            if field not in content:
                missing_fields.append(field)
            elif not content[field] or (isinstance(content[field], str) and not content[field].strip()):
                empty_fields.append(field)
        
        if missing_fields:
            return {
                'valid': False,
                'message': f'ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_fields}'
            }
        
        if empty_fields:
            return {
                'valid': False,
                'message': f'å­—æ®µå†…å®¹ä¸ºç©º: {empty_fields}'
            }
        
        # æ£€æŸ¥å†…å®¹é•¿åº¦
        if len(content['title']) > 200:
            return {
                'valid': False,
                'message': 'æ ‡é¢˜è¿‡é•¿ï¼ˆæœ€å¤š200å­—ç¬¦ï¼‰'
            }
        
        if len(content['summary']) > 10000:
            return {
                'valid': False,
                'message': 'æ‘˜è¦è¿‡é•¿ï¼ˆæœ€å¤š10000å­—ç¬¦ï¼‰'
            }
        
        return {
            'valid': True,
            'message': 'å†…å®¹ç»“æ„æœ‰æ•ˆ'
        }


# å·¥å…·å‡½æ•°
def clean_html_content(html: str) -> str:
    """æ¸…ç†HTMLå†…å®¹
    
    Args:
        html: HTMLå†…å®¹
        
    Returns:
        æ¸…ç†åçš„HTML
    """
    # ç§»é™¤æ½œåœ¨çš„å±é™©æ ‡ç­¾å’Œå±æ€§
    import re
    
    # ç§»é™¤scriptæ ‡ç­¾
    html = re.sub(r'<script[^>]*>.*?</script>', '', html, flags=re.DOTALL | re.IGNORECASE)
    
    # ç§»é™¤on*äº‹ä»¶å±æ€§
    html = re.sub(r'on\w+="[^"]*"', '', html, flags=re.IGNORECASE)
    
    # ç§»é™¤javascript:é“¾æ¥
    html = re.sub(r'href="javascript:[^"]*"', 'href="#"', html, flags=re.IGNORECASE)
    
    return html


if __name__ == '__main__':
    # æµ‹è¯•å†…å®¹æ ¼å¼åŒ–æœåŠ¡
    test_config = {
        'site_title': 'Project Bach',
        'site_description': 'AIéŸ³é¢‘å¤„ç†ç»“æœå‘å¸ƒ',
        'theme': 'default'
    }
    
    formatter = ContentFormatter(test_config)
    
    # æµ‹è¯•å†…å®¹æ•°æ®
    test_content = {
        'title': 'æµ‹è¯•éŸ³é¢‘å¤„ç†ç»“æœ',
        'summary': 'è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ‘˜è¦ï¼ŒåŒ…å«äº†éŸ³é¢‘å¤„ç†çš„ä¸»è¦å†…å®¹å’Œå…³é”®ä¿¡æ¯ã€‚',
        'mindmap': '''# æµ‹è¯•æ€ç»´å¯¼å›¾
## ä¸»è¦å†…å®¹
- éŸ³é¢‘åˆ†æ
- å†…å®¹æå–
- ç»“æœç”Ÿæˆ

## æŠ€æœ¯æ–¹æ¡ˆ
- AIå¤„ç†
- è‡ªç„¶è¯­è¨€å¤„ç†
- å†…å®¹æ ¼å¼åŒ–''',
        'processed_time': '2025-08-21T10:30:00',
        'original_file': 'test_audio.mp3',
        'anonymized_names': {
            'å¼ ä¸‰': 'ç‹æ˜',
            'æå››': 'åˆ˜å'
        },
        'file_size': '5.2MB',
        'audio_duration': '8åˆ†32ç§’'
    }
    
    # æ ¼å¼åŒ–æµ‹è¯•
    result = formatter.format_content(test_content)
    
    if result['success']:
        print("âœ… å†…å®¹æ ¼å¼åŒ–æµ‹è¯•æˆåŠŸ")
        print(f"æ ‡é¢˜: {result['content']['title']}")
        print(f"æ–‡ä»¶å: {result['content']['filename']}")
        print(f"HTMLé•¿åº¦: {len(result['content']['html'])} å­—ç¬¦")
    else:
        print(f"âŒ å†…å®¹æ ¼å¼åŒ–æµ‹è¯•å¤±è´¥: {result['error']}")
        
    # æµ‹è¯•ç´¢å¼•åˆ›å»º
    test_results = [
        {'title': 'éŸ³é¢‘1', 'date': '2025-08-21', 'file': 'audio1.html', 'summary': 'éŸ³é¢‘1æ‘˜è¦'},
        {'title': 'éŸ³é¢‘2', 'date': '2025-08-20', 'file': 'audio2.html', 'summary': 'éŸ³é¢‘2æ‘˜è¦'}
    ]
    
    index_result = formatter.create_site_index(test_results)
    
    if index_result['success']:
        print("âœ… ç´¢å¼•åˆ›å»ºæµ‹è¯•æˆåŠŸ")
        print(f"åŒ…å«é¡¹ç›®æ•°: {index_result['content']['total_items']}")
    else:
        print(f"âŒ ç´¢å¼•åˆ›å»ºæµ‹è¯•å¤±è´¥: {index_result['error']}")